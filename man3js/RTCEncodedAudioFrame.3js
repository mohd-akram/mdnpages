.\" Automatically generated by Pandoc 3.2.1
.\"
.TH "RTCEncodedAudioFrame" "JS" "August 5, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
RTCEncodedAudioFrame \- RTCEncodedAudioFrame
.SH SYNOPSIS
\f[B]Note:\f[R] This feature is available in Dedicated Web Workers.
.PP
The \f[B]\f[CB]RTCEncodedAudioFrame\f[B]\f[R] of the WebRTC API
represents an encoded audio frame in the WebRTC receiver or sender
pipeline, which may be modified using a WebRTC Encoded Transform.
.PP
The interface provides methods and properties to get metadata about the
frame, allowing its format and order in the sequence of frames to be
determined.
The \f[CR]data\f[R] property gives access to the encoded frame data as a
buffer, which might be encrypted, or otherwise modified by a transform.
.RS
.PP
\f[B]Note:\f[R] This feature is available in \f[I]Dedicated\f[R] Web
Workers.
.RE
.SH INSTANCE PROPERTIES
.TP
\f[B]RTCEncodedAudioFrame.timestamp\f[R] \f[I](read\-only)\f[R] \f[I](deprecated)\f[R] \f[I](non\-standard)\f[R]
Returns the timestamp at which sampling of the frame started.
.TP
\f[B]RTCEncodedAudioFrame.data\f[R]
Return a buffer containing the encoded frame data.
.SH INSTANCE METHODS
.TP
\f[B]RTCEncodedAudioFrame.getMetadata()\f[R]
Returns the metadata associated with the frame.
.SH EXAMPLES
This code snippet shows a handler for the \f[CR]rtctransform\f[R] event
in a \f[CR]Worker\f[R] that implements a \f[CR]TransformStream\f[R], and
pipes encoded frames through it from the
\f[CR]event.transformer.readable\f[R] to
\f[CR]event.transformer.writable\f[R] (\f[CR]event.transformer\f[R] is a
\f[CR]RTCRtpScriptTransformer\f[R], the worker\-side counterpart of
\f[CR]RTCRtpScriptTransform\f[R]).
.PP
If the tranformer is inserted into an audio stream, the
\f[CR]transform()\f[R] method is called with a
\f[CR]RTCEncodedAudioFrame\f[R] whenever a new frame is enqueued on
\f[CR]event.transformer.readable\f[R].
The \f[CR]transform()\f[R] method shows how this might be read, modified
using a fictional encryption function, and then enqueued on the
controller (this ultimately pipes it through to the
\f[CR]event.transformer.writable\f[R], and then back into the WebRTC
pipline).
.IP
.EX
addEventListener(\[dq]rtctransform\[dq], (event) \f[B]=>\f[R] {
  \f[B]const\f[R] \f[B]async\f[R] transform = \f[B]new\f[R] TransformStream({
    \f[B]async\f[R] transform(encodedFrame, controller) {
      \f[I]// Reconstruct the original frame.\f[R]
      \f[B]const\f[R] view = \f[B]new\f[R] DataView(encodedFrame.data);

      \f[I]// Construct a new buffer\f[R]
      \f[B]const\f[R] newData = \f[B]new\f[R] ArrayBuffer(encodedFrame.data.byteLength);
      \f[B]const\f[R] newView = \f[B]new\f[R] DataView(newData);

      \f[I]//Encrypt frame bytes using the encryptFunction() method (not shown)\f[R]
      \f[B]for\f[R] (\f[B]let\f[R] i = 0; i < encodedFrame.data.byteLength; ++i) {
        \f[B]const\f[R] encryptedByte = encryptFunction(\[ti]view.getInt8(i));
        newView.setInt8(i, encryptedByte);
      }

      encodedFrame.data = newData;
      controller.enqueue(encodedFrame);
    },
  });
  event.transformer.readable
    .pipeThrough(transform)
    .pipeTo(event.transformer.writable);
});
.EE
.PP
Note that more complete examples are provided in Using WebRTC Encoded
Transforms.
.SH SEE ALSO
.IP \[bu] 2
Using WebRTC Encoded Transforms
.IP \[bu] 2
\f[CR]TransformStream\f[R]
.IP \[bu] 2
\f[CR]RTCRtpScriptTransformer\f[R]
.IP \[bu] 2
\f[CR]RTCEncodedVideoFrame\f[R]

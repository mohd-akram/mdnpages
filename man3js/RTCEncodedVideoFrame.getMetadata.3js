.\" Automatically generated by Pandoc 3.4
.\"
.TH "RTCEncodedVideoFrame.getMetadata" "JS" "December 2, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
RTCEncodedVideoFrame.getMetadata \- RTCEncodedVideoFrame: getMetadata()
method
.SH SYNOPSIS
\f[B]Note:\f[R] This feature is available in Dedicated Web Workers.
.PP
The \f[B]\f[CB]getMetadata()\f[B]\f[R] method of the
\f[CR]RTCEncodedVideoFrame\f[R] interface returns an object containing
the metadata associated with the frame.
.PP
This includes information about the frame, including its size, video
encoding, other frames needed to construct a full image, timestamp, and
other information.
.SH SYNTAX
.IP
.EX
getMetadata()
.EE
.SS Parameters
None.
.SS Return value
An object with the following properties:
.TP
\f[B]frameId\f[R]
A positive integer value indicating the id of this frame.
.TP
\f[B]dependencies\f[R]
An \f[CR]Array\f[R] of positive integers indicating the frameIds of
frames on which this frame depends.
For a key frame this will be empty, as a key frame contains all the
information it needs to construct the image.
For a delta frame this will list all the frames needed to render this
frame.
The type of frame can be determined using
\f[CR]RTCEncodedVideoFrame.type\f[R].
.TP
\f[B]width\f[R]
A positive integer indicating the width of the frame.
The maximum value is 65535.
.TP
\f[B]height\f[R]
A positive integer indicating the height of the frame.
The maximum value is 65535.
.TP
\f[B]spatialIndex\f[R]
A positive integer indicating the spatial index of the frame.
Some codecs allow generation of layers of frames with different layers
of resolutions.
Frames in higher layers can be selectively dropped in order to reduce
bit rate when needed, while maintaining acceptable video quality.
.TP
\f[B]temporalIndex\f[R]
A positive integer indicating the temporal index of the frame.
Some codecs group frames in layers, based on whether dropping the a
frame will prevent others from being decoded.
Frames in higher layers can be selectively dropped in order to reduce
bit rate when needed, while maintaining acceptable video quality.
.TP
\f[B]synchronizationSource\f[R]
A positive integer value indicating synchronization source
(\[lq]ssrc\[rq]) of the stream of RTP packets that are described by this
encoded video frame.
A source might be something like a camera or microphone, or some kind of
mixer app that combines multiple sources.
All packets from the same source share the same time source and sequence
space, and so can be ordered relative to each other.
Note two frames with the same value refer to the same source (for more
information see \f[CR]RTCInboundRtpStreamStats.ssrc\f[R]).
.TP
\f[B]payloadType\f[R]
A positive integer value in the range from 0 to 127 that describes the
format of the RTP payload.
The mappings of values to formats is defined in RFC3550.
.TP
\f[B]contributingSources\f[R]
An \f[CR]Array\f[R] of sources (ssrc) that have contributed to the
frame.
Consider the case of a conferencing application that combines the audio
and video from multiple users.
The \f[CR]synchronizationSource\f[R] would include the ssrc of the
application, while \f[CR]contributingSources\f[R] would include the ssrc
values of all the individual video and audio sources.
.TP
\f[B]timestamp\f[R]
The \c
.UR https://en.wikipedia.org/wiki/Presentation_timestamp
media presentation timestamp (PTS)
.UE \c
\ in microseconds of raw frame, matching the timestamp for raw frames
which correspond to this frame.
This is used to synchronize separate video, audio, subtitle and other
streams belonging to the same presentation.
.SH EXAMPLES
This example WebRTC encoded transform implementation shows how you might
get the frame metadata in a \f[CR]transform()\f[R] function and log it.
.IP
.EX
addEventListener(\[dq]rtctransform\[dq], (event) \f[B]=>\f[R] {
  \f[B]const\f[R] \f[B]async\f[R] transform = \f[B]new\f[R] TransformStream({
    \f[B]async\f[R] transform(encodedFrame, controller) {

      \f[I]// Get the metadata and log\f[R]
      \f[B]const\f[R] frameMetaData = encodedFrame.getMetadata();
      console.log(frameMetaData)

      \f[I]// Enqueue the frame without modifying\f[R]
      controller.enqueue(encodedFrame);
    },
  });
  event.transformer.readable
    .pipeThrough(transform)
    .pipeTo(event.transformer.writable);
});
.EE
.PP
The resulting object from a local webcam might look like the one shown
below.
Note that there are no contributing sources because there is just one
source.
.IP
.EX
{
  \[dq]contributingSources\[dq]: [],
  \[dq]dependencies\[dq]: [
    405
  ],
  \[dq]frameId\[dq]: 406,
  \[dq]height\[dq]: 480,
  \[dq]payloadType\[dq]: 120,
  \[dq]spatialIndex\[dq]: 0,
  \[dq]synchronizationSource\[dq]: 3956716931,
  \[dq]temporalIndex\[dq]: 0,
  \[dq]width\[dq]: 640
}
.EE
.SH SEE ALSO
.IP \[bu] 2
Using WebRTC Encoded Transforms

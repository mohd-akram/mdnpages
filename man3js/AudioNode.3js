.\" Automatically generated by Pandoc 3.4
.\"
.TH "AudioNode" "JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioNode \- AudioNode
.SH SYNOPSIS
The \f[B]\f[CB]AudioNode\f[B]\f[R] interface is a generic interface for
representing an audio processing module.
.PP
Examples include:
.IP \[bu] 2
an audio source (e.g.\ an HTML \f[CR]<audio>\f[R] or \f[CR]<video>\f[R]
element, an \f[CR]OscillatorNode\f[R], etc.),
.IP \[bu] 2
the audio destination,
.IP \[bu] 2
intermediate processing module (e.g.\ a filter like
\f[CR]BiquadFilterNode\f[R] or \f[CR]ConvolverNode\f[R]), or
.IP \[bu] 2
volume control (like \f[CR]GainNode\f[R])
.RS
.PP
\f[B]Note:\f[R] An \f[CR]AudioNode\f[R] can be target of events,
therefore it implements the \f[CR]EventTarget\f[R] interface.
.RE
.SH INSTANCE PROPERTIES
.TP
\f[B]AudioNode.context\f[R] \f[I](read\-only)\f[R]
Returns the associated \f[CR]BaseAudioContext\f[R], that is the object
representing the processing graph the node is participating in.
.TP
\f[B]AudioNode.numberOfInputs\f[R] \f[I](read\-only)\f[R]
Returns the number of inputs feeding the node.
Source nodes are defined as nodes having a \f[CR]numberOfInputs\f[R]
property with a value of \f[CR]0\f[R].
.TP
\f[B]AudioNode.numberOfOutputs\f[R] \f[I](read\-only)\f[R]
Returns the number of outputs coming out of the node.
Destination nodes \[em] like \f[CR]AudioDestinationNode\f[R] \[em] have
a value of \f[CR]0\f[R] for this attribute.
.TP
\f[B]AudioNode.channelCount\f[R]
Represents an integer used to determine how many channels are used when
up\-mixing and down\-mixing connections to any inputs to the node.
Its usage and precise definition depend on the value of
\f[CR]AudioNode.channelCountMode\f[R].
.TP
\f[B]AudioNode.channelCountMode\f[R]
Represents an enumerated value describing the way channels must be
matched between the node\[cq]s inputs and outputs.
.TP
\f[B]AudioNode.channelInterpretation\f[R]
Represents an enumerated value describing the meaning of the channels.
This interpretation will define how audio up\-mixing and down\-mixing
will happen.
The possible values are \f[CR]\[dq]speakers\[dq]\f[R] or
\f[CR]\[dq]discrete\[dq]\f[R].
.SH INSTANCE METHODS
\f[I]Also implements methods from the interface\f[R]
\f[CR]EventTarget\f[R].
.TP
\f[B]AudioNode.connect()\f[R]
Allows us to connect the output of this node to be input into another
node, either as audio data or as the value of an \f[CR]AudioParam\f[R].
.TP
\f[B]AudioNode.disconnect()\f[R]
Allows us to disconnect the current node from another one it is already
connected to.
.SH DESCRIPTION
.SS The audio routing graph
[IMAGE: AudioNodes participating in an AudioContext create an audio
routing graph.]
AudioNodes participating in an AudioContext create an audio routing
graph.
.PP
Each \f[CR]AudioNode\f[R] has inputs and outputs, and multiple audio
nodes are connected to build a \f[I]processing graph\f[R].
This graph is contained in an \f[CR]AudioContext\f[R], and each audio
node can only belong to one audio context.
.PP
A \f[I]source node\f[R] has zero inputs but one or multiple outputs, and
can be used to generate sound.
On the other hand, a \f[I]destination node\f[R] has no outputs; instead,
all its inputs are directly played back on the speakers (or whatever
audio output device the audio context uses).
In addition, there are \f[I]processing nodes\f[R] which have inputs and
outputs.
The exact processing done varies from one \f[CR]AudioNode\f[R] to
another but, in general, a node reads its inputs, does some
audio\-related processing, and generates new values for its outputs, or
lets the audio pass through (for example in the \f[CR]AnalyserNode\f[R],
where the result of the processing is accessed separately).
.PP
The more nodes in a graph, the higher the latency will be.
For example, if your graph has a latency of 500ms, when the source node
plays a sound, it will take half a second until that sound can be heard
on your speakers (or even longer because of latency in the underlying
audio device).
Therefore, if you need to have interactive audio, keep the graph as
small as possible, and put user\-controlled audio nodes at the end of a
graph.
For example, a volume control (\f[CR]GainNode\f[R]) should be the last
node so that volume changes take immediate effect.
.PP
Each input and output has a given amount of \f[I]channels\f[R].
For example, mono audio has one channel, while stereo audio has two
channels.
The Web Audio API will up\-mix or down\-mix the number of channels as
required; check the Web Audio spec for details.
.PP
For a list of all audio nodes, see the Web Audio API homepage.
.SS Creating an \f[CR]AudioNode\f[R]
There are two ways to create an \f[CR]AudioNode\f[R]: via the
\f[I]constructor\f[R] and via the \f[I]factory method\f[R].
.IP
.EX
\f[I]// constructor\f[R]
\f[B]const\f[R] analyserNode = \f[B]new\f[R] AnalyserNode(audioCtx, {
  fftSize: 2048,
  maxDecibels: \-25,
  minDecibels: \-60,
  smoothingTimeConstant: 0.5,
});
.EE
.IP
.EX
\f[I]// factory method\f[R]
\f[B]const\f[R] analyserNode = audioCtx.createAnalyser();
analyserNode.fftSize = 2048;
analyserNode.maxDecibels = \-25;
analyserNode.minDecibels = \-60;
analyserNode.smoothingTimeConstant = 0.5;
.EE
.PP
You are free to use either constructors or factory methods, or mix both,
however there are advantages to using the constructors:
.IP \[bu] 2
All parameters can be set during construction time and don\[cq]t need to
be set individually.
.IP \[bu] 2
You can \c
.UR https://github.com/WebAudio/web-audio-api/issues/251
sub\-class an audio node
.UE \c
\&.
While the actual processing is done internally by the browser and cannot
be altered, you could write a wrapper around an audio node to provide
custom properties and methods.
.IP \[bu] 2
Slightly better performance: In both Chrome and Firefox, the factory
methods call the constructors internally.
.PP
\f[I]Brief history:\f[R] The first version of the Web Audio spec only
defined the factory methods.
After a \c
.UR https://github.com/WebAudio/web-audio-api/issues/250
design review in October 2013
.UE \c
, it was decided to add constructors because they have numerous benefits
over factory methods.
The constructors were added to the spec from August to October 2016.
Factory methods continue to be included in the spec and are not
deprecated.
.SH EXAMPLE
This simple snippet of code shows the creation of some audio nodes, and
how the \f[CR]AudioNode\f[R] properties and methods can be used.
You can find examples of such usage on any of the examples linked to on
the Web Audio API landing page (for example \c
.UR https://github.com/mdn/webaudio-examples/tree/main/violent-theremin
Violent Theremin
.UE \c
).
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();

\f[B]const\f[R] oscillator = \f[B]new\f[R] OscillatorNode(audioCtx);
\f[B]const\f[R] gainNode = \f[B]new\f[R] GainNode(audioCtx);

oscillator.connect(gainNode).connect(audioCtx.destination);

oscillator.context;
oscillator.numberOfInputs;
oscillator.numberOfOutputs;
oscillator.channelCount;
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

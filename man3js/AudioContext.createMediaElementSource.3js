.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "AUDIOCONTEXT.CREATEMEDIAELEMENTSOURCE" "3JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioContext.createMediaElementSource \- AudioContext:
createMediaElementSource() method
.SH SYNOPSIS
The \f[CR]createMediaElementSource()\f[R] method of the
\f[CR]AudioContext\f[R] Interface is used to create a new
\f[CR]MediaElementAudioSourceNode\f[R] object, given an existing HTML
\f[CR]<audio>\f[R] or \f[CR]<video>\f[R] element, the audio from which
can then be played and manipulated.
.PP
For more details about media element audio source nodes, check out the
\f[CR]MediaElementAudioSourceNode\f[R] reference page.
.SH SYNTAX
.IP
.EX
createMediaElementSource(myMediaElement)
.EE
.SS Parameters
.TP
\f[B]myMediaElement\f[R]
An \f[CR]HTMLMediaElement\f[R] object that you want to feed into an
audio processing graph to manipulate.
.SS Return value
A \f[CR]MediaElementAudioSourceNode\f[R].
.SH EXAMPLES
This simple example creates a source from an \f[CR]<audio>\f[R] element
using \f[CR]createMediaElementSource()\f[R], then passes the audio
through a \f[CR]GainNode\f[R] before feeding it into the
\f[CR]AudioDestinationNode\f[R] for playback.
When the mouse pointer is moved, the \f[CR]updatePage()\f[R] function is
invoked, which calculates the current gain as a ratio of mouse Y
position divided by overall window height.
You can therefore increase and decrease the volume of the playing music
by moving the mouse pointer up and down.
.RS
.PP
\f[B]Note:\f[R] You can also \c
.UR https://mdn.github.io/webaudio-examples/media-source-buffer/
view this example running live
.UE \c
, or \c
.UR https://github.com/mdn/webaudio-examples/tree/main/media-source-buffer
view the source
.UE \c
\&.
.RE
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();
\f[B]const\f[R] myAudio = document.querySelector(\(dqaudio\(dq);

\f[I]// Create a MediaElementAudioSourceNode\f[R]
\f[I]// Feed the HTMLMediaElement into it\f[R]
\f[B]const\f[R] source = audioCtx.createMediaElementSource(myAudio);

\f[I]// Create a gain node\f[R]
\f[B]const\f[R] gainNode = audioCtx.createGain();

\f[I]// Create variables to store mouse pointer Y coordinate\f[R]
\f[I]// and HEIGHT of screen\f[R]
\f[B]let\f[R] curY;
\f[B]const\f[R] HEIGHT = window.innerHeight;

\f[I]// Get new mouse pointer coordinates when mouse is moved\f[R]
\f[I]// then set new gain value\f[R]
document.onmousemove = updatePage;

\f[B]function\f[R] updatePage(e) {
  curY = e.pageY;
  gainNode.gain.value = curY / HEIGHT;
}

\f[I]// Connect the AudioBufferSourceNode to the gainNode\f[R]
\f[I]// and the gainNode to the destination, so we can play the\f[R]
\f[I]// music and adjust the volume using the mouse cursor\f[R]
source.connect(gainNode);
gainNode.connect(audioCtx.destination);
.EE
.RS
.PP
\f[B]Note:\f[R] As a consequence of calling
\f[CR]createMediaElementSource()\f[R], audio playback from the
\f[CR]HTMLMediaElement\f[R] will be re\-routed into the processing graph
of the AudioContext.
So playing/pausing the media can still be done through the media element
API and the player controls.
.RE
.SH SEE ALSO
.IP \(bu 2
Using the Web Audio API

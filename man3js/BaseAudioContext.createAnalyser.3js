.\" Automatically generated by Pandoc 3.1.12.3
.\"
.TH "BaseAudioContext.createAnalyser" "JS" "January 16, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
BaseAudioContext.createAnalyser \- BaseAudioContext: createAnalyser()
method
.SH SYNOPSIS
The \f[CR]createAnalyser()\f[R] method of the
\f[CR]BaseAudioContext\f[R] interface creates an
\f[CR]AnalyserNode\f[R], which can be used to expose audio time and
frequency data and create data visualizations.
.RS
.PP
\f[B]Note:\f[R] The \f[CR]AnalyserNode()\f[R] constructor is the
recommended way to create an \f[CR]AnalyserNode\f[R]; see Creating an
AudioNode.
.RE
.RS
.PP
\f[B]Note:\f[R] For more on using this node, see the
\f[CR]AnalyserNode\f[R] page.
.RE
.SH SYNTAX
.IP
.EX
createAnalyser()
.EE
.SS Parameters
None.
.SS Return value
An \f[CR]AnalyserNode\f[R].
.SH EXAMPLES
The following example shows basic usage of an AudioContext to create an
Analyser node, then use requestAnimationFrame() to collect time domain
data repeatedly and draw an \[lq]oscilloscope style\[rq] output of the
current audio input.
For more complete applied examples/information, check out our \c
.UR https://mdn.github.io/webaudio-examples/voice-change-o-matic/
Voice\-change\-O\-matic
.UE \c
\ demo (see \c
.UR https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic/scripts/app.js#L108-L193
app.js lines 108\-193
.UE \c
\ for relevant code).
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] (window.AudioContext || window.webkitAudioContext)();
\f[B]const\f[R] analyser = audioCtx.createAnalyser();

\f[I]// \&...\f[R]

analyser.fftSize = 2048;
\f[B]const\f[R] bufferLength = analyser.frequencyBinCount;
\f[B]const\f[R] dataArray = \f[B]new\f[R] Uint8Array(bufferLength);
analyser.getByteTimeDomainData(dataArray);

\f[I]// draw an oscilloscope of the current audio source\f[R]

\f[B]function\f[R] draw() {
  drawVisual = requestAnimationFrame(draw);

  analyser.getByteTimeDomainData(dataArray);

  canvasCtx.fillStyle = \[dq]rgb(200 200 200)\[dq];
  canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);

  canvasCtx.lineWidth = 2;
  canvasCtx.strokeStyle = \[dq]rgb(0 0 0)\[dq];

  canvasCtx.beginPath();

  \f[B]const\f[R] sliceWidth = (WIDTH * 1.0) / bufferLength;
  \f[B]let\f[R] x = 0;

  \f[B]for\f[R] (\f[B]let\f[R] i = 0; i < bufferLength; i++) {
    \f[B]const\f[R] v = dataArray[i] / 128.0;
    \f[B]const\f[R] y = (v * HEIGHT) / 2;

    \f[B]if\f[R] (i === 0) {
      canvasCtx.moveTo(x, y);
    } \f[B]else\f[R] {
      canvasCtx.lineTo(x, y);
    }

    x += sliceWidth;
  }

  canvasCtx.lineTo(canvas.width, canvas.height / 2);
  canvasCtx.stroke();
}

draw();
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "SPEECHRECOGNITION" "3JS" "April 10, 2025" "JavaScript" "JavaScript Reference Manual"
.SH NAME
SpeechRecognition \- SpeechRecognition
.SH SYNOPSIS
The \f[B]\f[CB]SpeechRecognition\f[B]\f[R] interface of the Web Speech
API is the controller interface for the recognition service; this also
handles the \f[CR]SpeechRecognitionEvent\f[R] sent from the recognition
service.
.RS
.PP
\f[B]Note:\f[R] On some browsers, like Chrome, using Speech Recognition
on a web page involves a server\-based recognition engine.
Your audio is sent to a web service for recognition processing, so it
won\(cqt work offline.
.RE
.SH CONSTRUCTOR
.TP
\f[B]SpeechRecognition()\f[R]
Creates a new \f[CR]SpeechRecognition\f[R] object.
.SH INSTANCE PROPERTIES
\f[I]\f[CI]SpeechRecognition\f[I] also inherits properties from its
parent interface, \f[CI]EventTarget\f[I].\f[R]
.TP
\f[B]SpeechRecognition.grammars\f[R]
Returns and sets a collection of \f[CR]SpeechGrammar\f[R] objects that
represent the grammars that will be understood by the current
\f[CR]SpeechRecognition\f[R].
.TP
\f[B]SpeechRecognition.lang\f[R]
Returns and sets the language of the current
\f[CR]SpeechRecognition\f[R].
If not specified, this defaults to the HTML \f[CR]lang\f[R] attribute
value, or the user agent\(cqs language setting if that isn\(cqt set
either.
.TP
\f[B]SpeechRecognition.continuous\f[R]
Controls whether continuous results are returned for each recognition,
or only a single result.
Defaults to single (\f[CR]false\f[R].)
.TP
\f[B]SpeechRecognition.interimResults\f[R]
Controls whether interim results should be returned (\f[CR]true\f[R]) or
not (\f[CR]false\f[R].)
Interim results are results that are not yet final (e.g., the
\f[CR]SpeechRecognitionResult.isFinal\f[R] property is
\f[CR]false\f[R].)
.TP
\f[B]SpeechRecognition.maxAlternatives\f[R]
Sets the maximum number of \f[CR]SpeechRecognitionAlternative\f[R]s
provided per result.
The default value is 1.
.SH INSTANCE METHODS
\f[I]\f[CI]SpeechRecognition\f[I] also inherits methods from its parent
interface, \f[CI]EventTarget\f[I].\f[R]
.TP
\f[B]SpeechRecognition.abort()\f[R]
Stops the speech recognition service from listening to incoming audio,
and doesn\(cqt attempt to return a \f[CR]SpeechRecognitionResult\f[R].
.TP
\f[B]SpeechRecognition.start()\f[R]
Starts the speech recognition service listening to incoming audio with
intent to recognize grammars associated with the current
\f[CR]SpeechRecognition\f[R].
.TP
\f[B]SpeechRecognition.stop()\f[R]
Stops the speech recognition service from listening to incoming audio,
and attempts to return a \f[CR]SpeechRecognitionResult\f[R] using the
audio captured so far.
.SH EVENTS
Listen to these events using \f[CR]addEventListener()\f[R] or by
assigning an event listener to the \f[CR]oneventname\f[R] property of
this interface.
.TP
\f[B]audiostart\f[R]
Fired when the user agent has started to capture audio.
Also available via the \f[CR]onaudiostart\f[R] property.
.TP
\f[B]audioend\f[R]
Fired when the user agent has finished capturing audio.
Also available via the \f[CR]onaudioend\f[R] property.
.TP
\f[B]end\f[R]
Fired when the speech recognition service has disconnected.
Also available via the \f[CR]onend\f[R] property.
.TP
\f[B]error\f[R]
Fired when a speech recognition error occurs.
Also available via the \f[CR]onerror\f[R] property.
.TP
\f[B]nomatch\f[R]
Fired when the speech recognition service returns a final result with no
significant recognition.
This may involve some degree of recognition, which doesn\(cqt meet or
exceed the \f[CR]confidence\f[R] threshold.
Also available via the \f[CR]onnomatch\f[R] property.
.TP
\f[B]result\f[R]
Fired when the speech recognition service returns a result \(em a word
or phrase has been positively recognized and this has been communicated
back to the app.
Also available via the \f[CR]onresult\f[R] property.
.TP
\f[B]soundstart\f[R]
Fired when any sound \(em recognizable speech or not \(em has been
detected.
Also available via the \f[CR]onsoundstart\f[R] property.
.TP
\f[B]soundend\f[R]
Fired when any sound \(em recognizable speech or not \(em has stopped
being detected.
Also available via the \f[CR]onsoundend\f[R] property.
.TP
\f[B]speechstart\f[R]
Fired when sound that is recognized by the speech recognition service as
speech has been detected.
Also available via the \f[CR]onspeechstart\f[R] property.
.TP
\f[B]speechend\f[R]
Fired when speech recognized by the speech recognition service has
stopped being detected.
Also available via the \f[CR]onspeechend\f[R] property.
.TP
\f[B]start\f[R]
Fired when the speech recognition service has begun listening to
incoming audio with intent to recognize grammars associated with the
current \f[CR]SpeechRecognition\f[R].
Also available via the \f[CR]onstart\f[R] property.
.SH EXAMPLES
In our simple \c
.UR https://github.com/mdn/dom-examples/tree/main/web-speech-api/speech-color-changer
Speech color changer
.UE \c
\ example, we create a new \f[CR]SpeechRecognition\f[R] object instance
using the \f[CR]SpeechRecognition()\f[R] constructor, create a new
\f[CR]SpeechGrammarList\f[R], and set it to be the grammar that will be
recognized by the \f[CR]SpeechRecognition\f[R] instance using the
\f[CR]SpeechRecognition.grammars\f[R] property.
.PP
After some other values have been defined, we then set it so that the
recognition service starts when a click event occurs (see
\f[CR]SpeechRecognition.start()\f[R].)
When a result has been successfully recognized, the \f[CR]result\f[R]
event fires, we extract the color that was spoken from the event object,
and then set the background color of the \f[CR]<html>\f[R] element to
that color.
.IP
.EX
\f[B]const\f[R] grammar =
  \(dq#JSGF V1.0; grammar colors; public <color> = aqua | azure | beige | bisque | black | blue | brown | chocolate | coral | crimson | cyan | fuchsia | ghostwhite | gold | goldenrod | gray | green | indigo | ivory | khaki | lavender | lime | linen | magenta | maroon | moccasin | navy | olive | orange | orchid | peru | pink | plum | purple | red | salmon | sienna | silver | snow | tan | teal | thistle | tomato | turquoise | violet | white | yellow ;\(dq;
\f[B]const\f[R] recognition = \f[B]new\f[R] SpeechRecognition();
\f[B]const\f[R] speechRecognitionList = \f[B]new\f[R] SpeechGrammarList();
speechRecognitionList.addFromString(grammar, 1);
recognition.grammars = speechRecognitionList;
recognition.continuous = \f[B]false\f[R];
recognition.lang = \(dqen\-US\(dq;
recognition.interimResults = \f[B]false\f[R];
recognition.maxAlternatives = 1;

\f[B]const\f[R] diagnostic = document.querySelector(\(dq.output\(dq);
\f[B]const\f[R] bg = document.querySelector(\(dqhtml\(dq);

document.body.onclick = () \f[B]=>\f[R] {
  recognition.start();
  console.log(\(dqReady to receive a color command.\(dq);
};

recognition.onresult = (event) \f[B]=>\f[R] {
  \f[B]const\f[R] color = event.results[0][0].transcript;
  diagnostic.textContent = \(gaResult received: ${color}\(ga;
  bg.style.backgroundColor = color;
};
.EE
.SH SEE ALSO
.IP \(bu 2
Web Speech API

.\" Automatically generated by Pandoc 3.2.1
.\"
.TH "AudioContext" "JS" "July 25, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioContext \- AudioContext
.SH SYNOPSIS
The \f[CR]AudioContext\f[R] interface represents an audio\-processing
graph built from audio modules linked together, each represented by an
\f[CR]AudioNode\f[R].
.PP
An audio context controls both the creation of the nodes it contains and
the execution of the audio processing, or decoding.
You need to create an \f[CR]AudioContext\f[R] before you do anything
else, as everything happens inside a context.
It\[cq]s recommended to create one AudioContext and reuse it instead of
initializing a new one each time, and it\[cq]s OK to use a single
\f[CR]AudioContext\f[R] for several different audio sources and pipeline
concurrently.
.SH CONSTRUCTOR
.TP
\f[B]AudioContext()\f[R]
Creates and returns a new \f[CR]AudioContext\f[R] object.
.SH INSTANCE PROPERTIES
\f[I]Also inherits properties from its parent interface,
\f[CI]BaseAudioContext\f[I].\f[R]
.TP
\f[B]AudioContext.baseLatency\f[R] \f[I](read\-only)\f[R]
Returns the number of seconds of processing latency incurred by the
\f[CR]AudioContext\f[R] passing the audio from the
\f[CR]AudioDestinationNode\f[R] to the audio subsystem.
.TP
\f[B]AudioContext.outputLatency\f[R] \f[I](read\-only)\f[R]
Returns an estimation of the output latency of the current audio
context.
.TP
\f[B]AudioContext.sinkId\f[R] \f[I](read\-only)\f[R] \f[I](experimental)\f[R] \f[I](secure context)\f[R]
Returns the sink ID of the current output audio device.
.SH INSTANCE METHODS
\f[I]Also inherits methods from its parent interface,
\f[CI]BaseAudioContext\f[I].\f[R]
.TP
\f[B]AudioContext.close()\f[R]
Closes the audio context, releasing any system audio resources that it
uses.
.TP
\f[B]AudioContext.createMediaElementSource()\f[R]
Creates a \f[CR]MediaElementAudioSourceNode\f[R] associated with an
\f[CR]HTMLMediaElement\f[R].
This can be used to play and manipulate audio from \f[CR]<video>\f[R] or
\f[CR]<audio>\f[R] elements.
.TP
\f[B]AudioContext.createMediaStreamSource()\f[R]
Creates a \f[CR]MediaStreamAudioSourceNode\f[R] associated with a
\f[CR]MediaStream\f[R] representing an audio stream which may come from
the local computer microphone or other sources.
.TP
\f[B]AudioContext.createMediaStreamDestination()\f[R]
Creates a \f[CR]MediaStreamAudioDestinationNode\f[R] associated with a
\f[CR]MediaStream\f[R] representing an audio stream which may be stored
in a local file or sent to another computer.
.TP
\f[B]AudioContext.createMediaStreamTrackSource()\f[R]
Creates a \f[CR]MediaStreamTrackAudioSourceNode\f[R] associated with a
\f[CR]MediaStream\f[R] representing an media stream track.
.TP
\f[B]AudioContext.getOutputTimestamp()\f[R]
Returns a new \f[CR]AudioTimestamp\f[R] object containing two audio
timestamp values relating to the current audio context.
.TP
\f[B]AudioContext.resume()\f[R]
Resumes the progression of time in an audio context that has previously
been suspended/paused.
.TP
\f[B]AudioContext.setSinkId()\f[R] \f[I](experimental)\f[R] \f[I](secure context)\f[R]
Sets the output audio device for the \f[CR]AudioContext\f[R].
.TP
\f[B]AudioContext.suspend()\f[R]
Suspends the progression of time in the audio context, temporarily
halting audio hardware access and reducing CPU/battery usage in the
process.
.SH EVENTS
.TP
\f[B]sinkchange\f[R] \f[I](experimental)\f[R]
Fired when the output audio device (and therefore, the
\f[CR]AudioContext.sinkId\f[R]) has changed.
.SH EXAMPLES
Basic audio context declaration:
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();

\f[B]const\f[R] oscillatorNode = audioCtx.createOscillator();
\f[B]const\f[R] gainNode = audioCtx.createGain();
\f[B]const\f[R] finish = audioCtx.destination;
\f[I]// etc.\f[R]
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API
.IP \[bu] 2
\f[CR]OfflineAudioContext\f[R]

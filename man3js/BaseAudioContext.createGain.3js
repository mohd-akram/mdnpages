.\" Automatically generated by Pandoc 3.4
.\"
.TH "BaseAudioContext.createGain" "JS" "July 30, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
BaseAudioContext.createGain \- BaseAudioContext: createGain() method
.SH SYNOPSIS
The \f[CR]createGain()\f[R] method of the \f[CR]BaseAudioContext\f[R]
interface creates a \f[CR]GainNode\f[R], which can be used to control
the overall gain (or volume) of the audio graph.
.RS
.PP
\f[B]Note:\f[R] The \f[CR]GainNode()\f[R] constructor is the recommended
way to create a \f[CR]GainNode\f[R]; see Creating an AudioNode.
.RE
.SH SYNTAX
.IP
.EX
createGain()
.EE
.SS Parameters
None.
.SS Return value
A \f[CR]GainNode\f[R] which takes as input one or more audio sources and
outputs audio whose volume has been adjusted in gain (volume) to a level
specified by the node\[cq]s \f[CR]GainNode.gain\f[R] a\-rate parameter.
.SH EXAMPLES
The following example shows basic usage of an \f[CR]AudioContext\f[R] to
create a \f[CR]GainNode\f[R], which is then used to mute and unmute the
audio when a Mute button is clicked by changing the \f[CR]gain\f[R]
property value.
.PP
The below snippet wouldn\[cq]t work as is \[em] for a complete working
example, check out our \c
.UR https://mdn.github.io/webaudio-examples/voice-change-o-matic/
Voice\-change\-O\-matic
.UE \c
\ demo (\c
.UR https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js
view source
.UE \c
\&.)
.IP
.EX
<\f[B]div\f[R]>
  <\f[B]button\f[R] class=\[dq]mute\[dq]>Mute button</\f[B]button\f[R]>
</\f[B]div\f[R]>
.EE
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();
\f[B]const\f[R] gainNode = audioCtx.createGain();
\f[B]const\f[R] mute = document.querySelector(\[dq].mute\[dq]);
\f[B]let\f[R] source;

\f[B]if\f[R] (navigator.mediaDevices.getUserMedia) {
  navigator.mediaDevices.getUserMedia(
    \f[I]// constraints \- only audio needed for this app\f[R]
    {
      audio: \f[B]true\f[R],
    },

    \f[I]// Success callback\f[R]
    (stream) \f[B]=>\f[R] {
      source = audioCtx.createMediaStreamSource(stream);
    },

    \f[I]// Error callback\f[R]
    (err) \f[B]=>\f[R] {
      console.error(\[ga]The following gUM error occurred: ${err}\[ga]);
    },
  );
} \f[B]else\f[R] {
  console.error(\[dq]getUserMedia not supported on your browser!\[dq]);
}

source.connect(gainNode);
gainNode.connect(audioCtx.destination);

\f[I]// \&...\f[R]

mute.onclick = () \f[B]=>\f[R] {
  \f[B]if\f[R] (mute.id === \[dq]\[dq]) {
    \f[I]// 0 means mute. If you still hear something, make sure you haven\[aq]t\f[R]
    \f[I]// connected your source into the output in addition to using the GainNode.\f[R]
    gainNode.gain.setValueAtTime(0, audioCtx.currentTime);
    mute.id = \[dq]activated\[dq];
    mute.textContent = \[dq]Unmute\[dq];
  } \f[B]else\f[R] {
    gainNode.gain.setValueAtTime(1, audioCtx.currentTime);
    mute.id = \[dq]\[dq];
    mute.textContent = \[dq]Mute\[dq];
  }
};
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

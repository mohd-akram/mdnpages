.\" Automatically generated by Pandoc 3.6.2
.\"
.TH "HTMLMediaElement.textTracks" "JS" "August 12, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
HTMLMediaElement.textTracks \- HTMLMediaElement: textTracks property
.SH SYNOPSIS
The read\-only \f[B]\f[CB]textTracks\f[B]\f[R] property on
\f[CR]HTMLMediaElement\f[R] objects returns a \f[CR]TextTrackList\f[R]
object listing all of the \f[CR]TextTrack\f[R] objects representing the
media element\[cq]s text tracks, in the same order as in the list of
text tracks.
.PP
You can detect when tracks are added to and removed from an
\f[CR]<audio>\f[R] or \f[CR]<video>\f[R] element using the
\f[CR]addtrack\f[R] and \f[CR]removetrack\f[R] events.
However, these events aren\[cq]t sent directly to the media element
itself.
Instead, they\[cq]re sent to the track list object of the
\f[CR]HTMLMediaElement\f[R] that corresponds to the type of track that
was added to the element
.PP
The returned list is \f[I]live\f[R]; that is, as tracks are added to and
removed from the media element, the list\[cq]s contents change
dynamically.
Once you have a reference to the list, you can monitor it for changes to
detect when new text tracks are added or existing ones removed.
.PP
See TextTrackList events to learn more about watching for changes to a
media element\[cq]s track list.
.SH VALUE
A \f[CR]TextTrackList\f[R] object representing the list of text tracks
included in the media element.
The list of tracks can be accessed using \f[CR]textTracks[n]\f[R] to get
the n\-th text track from the object\[cq]s list of text tracks, or using
the \f[CR]textTracks.getTrackById()\f[R] method.
.PP
Each track is represented by a \f[CR]TextTrack\f[R] object which
provides information about the track.
.SH EXAMPLES
We start with a \f[CR]<video>\f[R] that has several \f[CR]<track>\f[R]
children
.IP
.EX
<\f[B]video\f[R] controls poster=\[dq]/images/sample.gif\[dq]>
  <\f[B]source\f[R] src=\[dq]sample.mp4\[dq] type=\[dq]video/mp4\[dq] />
  <\f[B]source\f[R] src=\[dq]sample.ogv\[dq] type=\[dq]video/ogv\[dq] />
  <\f[B]track\f[R] kind=\[dq]captions\[dq] src=\[dq]sampleCaptions.vtt\[dq] srclang=\[dq]en\[dq] />
  <\f[B]track\f[R] kind=\[dq]descriptions\[dq] src=\[dq]sampleDescriptions.vtt\[dq] srclang=\[dq]en\[dq] />
  <\f[B]track\f[R] kind=\[dq]chapters\[dq] src=\[dq]sampleChapters.vtt\[dq] srclang=\[dq]en\[dq] />
  <\f[B]track\f[R] kind=\[dq]subtitles\[dq] src=\[dq]sampleSubtitles_de.vtt\[dq] srclang=\[dq]de\[dq] />
  <\f[B]track\f[R] kind=\[dq]subtitles\[dq] src=\[dq]sampleSubtitles_en.vtt\[dq] srclang=\[dq]en\[dq] />
  <\f[B]track\f[R] kind=\[dq]subtitles\[dq] src=\[dq]sampleSubtitles_ja.vtt\[dq] srclang=\[dq]ja\[dq] />
  <\f[B]track\f[R] kind=\[dq]subtitles\[dq] src=\[dq]sampleSubtitles_oz.vtt\[dq] srclang=\[dq]oz\[dq] />
  <\f[B]track\f[R] kind=\[dq]metadata\[dq] src=\[dq]keyStage1.vtt\[dq] srclang=\[dq]en\[dq] label=\[dq]Key Stage 1\[dq] />
  <\f[B]track\f[R] kind=\[dq]metadata\[dq] src=\[dq]keyStage2.vtt\[dq] srclang=\[dq]en\[dq] label=\[dq]Key Stage 2\[dq] />
  <\f[B]track\f[R] kind=\[dq]metadata\[dq] src=\[dq]keyStage3.vtt\[dq] srclang=\[dq]en\[dq] label=\[dq]Key Stage 3\[dq] />
</\f[B]video\f[R]>
.EE
.PP
The \f[CR]HTMLMediaElement.textTracks\f[R] returns a
\f[CR]textTracksList\f[R] through which we can iterate.
Here we print all the properties of each English track to the console.
.IP
.EX
\f[B]const\f[R] tracks = document.querySelector(\[dq]video\[dq]).textTracks;

\f[B]for\f[R] (\f[B]const\f[R] track \f[B]of\f[R] tracks) {
  \f[B]if\f[R] (track.language === \[dq]en\[dq]) {
    console.dir(track);
  }
}
.EE
.SH SEE ALSO
.IP \[bu] 2
\f[CR]HTMLMediaElement\f[R]: Interface used to define the
\f[CR]HTMLMediaElement.textTracks\f[R] property
.IP \[bu] 2
\f[CR]<audio>\f[R], \f[CR]<video>\f[R]
.IP \[bu] 2
\f[CR]AudioTrack\f[R], \f[CR]AudioTrackList\f[R]
.IP \[bu] 2
\f[CR]VideoTrack\f[R], \f[CR]VideoTrackList\f[R]
.IP \[bu] 2
\f[CR]addtrack\f[R], \f[CR]change\f[R], \f[CR]removetrack\f[R]:
AudioTrackList events
.IP \[bu] 2
\f[CR]addtrack\f[R], \f[CR]change\f[R], \f[CR]removetrack\f[R]:
VideoTrackList events

.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "ANALYSERNODE.GETFLOATTIMEDOMAINDATA" "3JS" "July 21, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AnalyserNode.getFloatTimeDomainData \- AnalyserNode:
getFloatTimeDomainData() method
.SH SYNOPSIS
The \f[B]\f[CB]getFloatTimeDomainData()\f[B]\f[R] method of the
\f[CR]AnalyserNode\f[R] Interface copies the current waveform, or
time\-domain, data into a \f[CR]Float32Array\f[R] array passed into it.
Each array value is a \f[I]sample\f[R], the magnitude of the signal at a
particular time.
.SH SYNTAX
.IP
.EX
getFloatTimeDomainData(array)
.EE
.SS Parameters
.TP
\f[B]array\f[R]
The \f[CR]Float32Array\f[R] that the time domain data will be copied to.
If the array has fewer elements than the
\f[CR]AnalyserNode.fftSize\f[R], excess elements are dropped.
If it has more elements than needed, excess elements are ignored.
.SS Return value
None (\f[CR]undefined\f[R]).
.SH EXAMPLES
The following example shows basic usage of an \f[CR]AudioContext\f[R] to
create an \f[CR]AnalyserNode\f[R], then \f[CR]requestAnimationFrame\f[R]
and \f[CR]<canvas>\f[R] to collect time domain data repeatedly and draw
an \(lqoscilloscope style\(rq output of the current audio input.
For more complete applied examples/information, check out our \c
.UR https://github.com/mdn/webaudio-examples/tree/main/voice-change-o-matic
Voice\-change\-O\-matic
.UE \c
\ demo (see \c
.UR https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193
app.js lines 108\(en193
.UE \c
\ for relevant code).
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();
\f[B]const\f[R] analyser = audioCtx.createAnalyser();

\f[I]// \&...\f[R]

analyser.fftSize = 1024;
\f[B]const\f[R] bufferLength = analyser.fftSize;
console.log(bufferLength);
\f[B]const\f[R] dataArray = \f[B]new\f[R] Float32Array(bufferLength);

canvasCtx.clearRect(0, 0, WIDTH, HEIGHT);

\f[B]function\f[R] draw() {
  drawVisual = requestAnimationFrame(draw);
  analyser.getFloatTimeDomainData(dataArray);

  canvasCtx.fillStyle = \(dqrgb(200 200 200)\(dq;
  canvasCtx.fillRect(0, 0, WIDTH, HEIGHT);
  canvasCtx.lineWidth = 2;
  canvasCtx.strokeStyle = \(dqrgb(0 0 0)\(dq;
  canvasCtx.beginPath();

  \f[B]const\f[R] sliceWidth = (WIDTH * 1.0) / bufferLength;
  \f[B]let\f[R] x = 0;

  \f[B]for\f[R] (\f[B]let\f[R] i = 0; i < bufferLength; i++) {
    \f[B]const\f[R] v = dataArray[i] * 200.0;
    \f[B]const\f[R] y = HEIGHT / 2 + v;

    \f[B]if\f[R] (i === 0) {
      canvasCtx.moveTo(x, y);
    } \f[B]else\f[R] {
      canvasCtx.lineTo(x, y);
    }
    x += sliceWidth;
  }

  canvasCtx.lineTo(canvas.width, canvas.height / 2);
  canvasCtx.stroke();
}

draw();
.EE
.SH SEE ALSO
.IP \(bu 2
Using the Web Audio API

.\" Automatically generated by Pandoc 3.2.1
.\"
.TH "AudioContext.createMediaStreamTrackSource" "JS" "March 12, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioContext.createMediaStreamTrackSource \- AudioContext:
createMediaStreamTrackSource() method
.SH SYNOPSIS
The \f[B]\f[CB]createMediaStreamTrackSource()\f[B]\f[R] method of the
\f[CR]AudioContext\f[R] interface creates and returns a
\f[CR]MediaStreamTrackAudioSourceNode\f[R] which represents an audio
source whose data comes from the specified \f[CR]MediaStreamTrack\f[R].
.PP
This differs from \f[CR]createMediaStreamSource()\f[R], which creates a
\f[CR]MediaStreamAudioSourceNode\f[R] whose audio comes from the audio
track in a specified \f[CR]MediaStream\f[R] whose \f[CR]id\f[R] is
first, lexicographically (alphabetically).
.SH SYNTAX
.IP
.EX
createMediaStreamTrackSource(track)
.EE
.SS Parameters
.TP
\f[B]track\f[R]
The \f[CR]MediaStreamTrack\f[R] to use as the source of all audio data
for the new node.
.SS Return value
A \f[CR]MediaStreamTrackAudioSourceNode\f[R] object which acts as a
source for audio data found in the specified audio track.
.SH EXAMPLES
In this example, \f[CR]getUserMedia()\f[R] is used to request access to
the user\[cq]s microphone.
Once that access is attained, an audio context is established and a
\f[CR]MediaStreamTrackAudioSourceNode\f[R] is created using
\f[CR]createMediaStreamTrackSource()\f[R], taking its audio from the
first audio track in the stream returned by \f[CR]getUserMedia()\f[R].
.PP
Then a \f[CR]BiquadFilterNode\f[R] is created using
\f[CR]createBiquadFilter()\f[R], and it\[cq]s configured as desired to
perform a lowshelf filter on the audio coming from the source.
The output from the microphone is then routed into the new biquad
filter, and the filter\[cq]s output is in turn routed to the audio
context\[cq]s \f[CR]destination\f[R].
.IP
.EX
navigator.mediaDevices
  .getUserMedia({ audio: \f[B]true\f[R], video: \f[B]false\f[R] })
  .then((stream) \f[B]=>\f[R] {
    audio.srcObject = stream;
    audio.onloadedmetadata = (e) \f[B]=>\f[R] {
      audio.play();
      audio.muted = \f[B]true\f[R];
    };

    \f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();
    \f[B]const\f[R] audioTracks = stream.getAudioTracks();
    \f[B]const\f[R] source = audioCtx.createMediaStreamTrackSource(audioTracks[0]);

    \f[B]const\f[R] biquadFilter = audioCtx.createBiquadFilter();
    biquadFilter.type = \[dq]lowshelf\[dq];
    biquadFilter.frequency.value = 3000;
    biquadFilter.gain.value = 20;

    source.connect(biquadFilter);
    biquadFilter.connect(audioCtx.destination);
  })
  .catch((err) \f[B]=>\f[R] {
    \f[I]// Handle getUserMedia() error\f[R]
  });
.EE
.SH SEE ALSO
.IP \[bu] 2
Web Audio API
.IP \[bu] 2
Using the Web Audio API
.IP \[bu] 2
\f[CR]MediaStreamTrackAudioSourceNode\f[R]

.\" Automatically generated by Pandoc 3.4
.\"
.TH "BaseAudioContext.createChannelSplitter" "JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
BaseAudioContext.createChannelSplitter \- BaseAudioContext:
createChannelSplitter() method
.SH SYNOPSIS
The \f[CR]createChannelSplitter()\f[R] method of the
\f[CR]BaseAudioContext\f[R] Interface is used to create a
\f[CR]ChannelSplitterNode\f[R], which is used to access the individual
channels of an audio stream and process them separately.
.RS
.PP
\f[B]Note:\f[R] The \f[CR]ChannelSplitterNode()\f[R] constructor is the
recommended way to create a \f[CR]ChannelSplitterNode\f[R]; see Creating
an AudioNode.
.RE
.SH SYNTAX
.IP
.EX
createChannelSplitter(numberOfOutputs)
.EE
.SS Parameters
.TP
\f[B]numberOfOutputs\f[R]
The number of channels in the input audio stream that you want to output
separately; the default is 6 if this parameter is not specified.
.SS Return value
A \f[CR]ChannelSplitterNode\f[R].
.SH EXAMPLES
The following simple example shows how you could separate a stereo track
(say, a piece of music), and process the left and right channel
differently.
To use them, you need to use the second and third parameters of the
\f[CR]AudioNode.connect(AudioNode)\f[R] method, which allow you to
specify the index of the channel to connect from and the index of the
channel to connect to.
.IP
.EX
\f[B]const\f[R] ac = \f[B]new\f[R] AudioContext();
ac.decodeAudioData(someStereoBuffer, (data) \f[B]=>\f[R] {
  \f[B]const\f[R] source = ac.createBufferSource();
  source.buffer = data;
  \f[B]const\f[R] splitter = ac.createChannelSplitter(2);
  source.connect(splitter);
  \f[B]const\f[R] merger = ac.createChannelMerger(2);

  \f[I]// Reduce the volume of the left channel only\f[R]
  \f[B]const\f[R] gainNode = ac.createGain();
  gainNode.gain.setValueAtTime(0.5, ac.currentTime);
  splitter.connect(gainNode, 0);

  \f[I]// Connect the splitter back to the second input of the merger: we\f[R]
  \f[I]// effectively swap the channels, here, reversing the stereo image.\f[R]
  gainNode.connect(merger, 0, 1);
  splitter.connect(merger, 1, 0);

  \f[B]const\f[R] dest = ac.createMediaStreamDestination();

  \f[I]// Because we have used a ChannelMergerNode, we now have a stereo\f[R]
  \f[I]// MediaStream we can use to pipe the Web Audio graph to WebRTC,\f[R]
  \f[I]// MediaRecorder, etc.\f[R]
  merger.connect(dest);
});
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

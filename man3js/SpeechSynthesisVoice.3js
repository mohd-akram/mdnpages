.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "SPEECHSYNTHESISVOICE" "3JS" "May 27, 2025" "JavaScript" "JavaScript Reference Manual"
.SH NAME
SpeechSynthesisVoice \- SpeechSynthesisVoice
.SH SYNOPSIS
The \f[B]\f[CB]SpeechSynthesisVoice\f[B]\f[R] interface of the Web
Speech API represents a voice that the system supports.
Every \f[CR]SpeechSynthesisVoice\f[R] has its own relative speech
service including information about language, name and URI.
.SH INSTANCE PROPERTIES
.TP
\f[B]SpeechSynthesisVoice.default\f[R] \f[I](read\-only)\f[R]
A boolean value indicating whether the voice is the default voice for
the current app language (\f[CR]true\f[R]), or not (\f[CR]false\f[R].)
.TP
\f[B]SpeechSynthesisVoice.lang\f[R] \f[I](read\-only)\f[R]
Returns a BCP 47 language tag indicating the language of the voice.
.TP
\f[B]SpeechSynthesisVoice.localService\f[R] \f[I](read\-only)\f[R]
A boolean value indicating whether the voice is supplied by a local
speech synthesizer service (\f[CR]true\f[R]), or a remote speech
synthesizer service (\f[CR]false\f[R].)
.TP
\f[B]SpeechSynthesisVoice.name\f[R] \f[I](read\-only)\f[R]
Returns a human\-readable name that represents the voice.
.TP
\f[B]SpeechSynthesisVoice.voiceURI\f[R] \f[I](read\-only)\f[R]
Returns the type of URI and location of the speech synthesis service for
this voice.
.SH EXAMPLES
The following snippet is excerpted from our \c
.UR https://github.com/mdn/dom-examples/blob/main/web-speech-api/speak-easy-synthesis/script.js
Speech synthesizer demo
.UE \c
\&.
.IP
.EX
\f[B]const\f[R] synth = window.speechSynthesis;
\f[B]function\f[R] populateVoiceList() {
  voices = synth.getVoices();

  \f[B]for\f[R] (\f[B]const\f[R] voice \f[B]of\f[R] voices) {
    \f[B]const\f[R] option = document.createElement(\(dqoption\(dq);
    option.textContent = \(ga${voice.name} (${voice.lang})\(ga;

    \f[B]if\f[R] (voice.default) {
      option.textContent += \(dq \(em DEFAULT\(dq;
    }

    option.setAttribute(\(dqdata\-lang\(dq, voice.lang);
    option.setAttribute(\(dqdata\-name\(dq, voice.name);
    voiceSelect.appendChild(option);
  }
}

populateVoiceList();
\f[B]if\f[R] (speechSynthesis.onvoiceschanged !== \f[B]undefined\f[R]) {
  speechSynthesis.onvoiceschanged = populateVoiceList;
}

inputForm.onsubmit = (event) \f[B]=>\f[R] {
  event.preventDefault();

  \f[B]const\f[R] utterThis = \f[B]new\f[R] SpeechSynthesisUtterance(inputTxt.value);
  \f[B]const\f[R] selectedOption =
    voiceSelect.selectedOptions[0].getAttribute(\(dqdata\-name\(dq);
  \f[B]for\f[R] (\f[B]const\f[R] voice \f[B]of\f[R] voices) {
    \f[B]if\f[R] (voice.name === selectedOption) {
      utterThis.voice = voice;
    }
  }
  utterThis.pitch = pitch.value;
  utterThis.rate = rate.value;
  synth.speak(utterThis);

  utterThis.onpause = (event) \f[B]=>\f[R] {
    \f[B]const\f[R] char = event.utterance.text.charAt(event.charIndex);
    console.log(
      \(gaSpeech paused at character ${event.charIndex} of \(dq${event.utterance.text}\(dq, which is \(dq${char}\(dq.\(ga,
    );
  };

  inputTxt.blur();
};
.EE
.SH SEE ALSO
.IP \(bu 2
Web Speech API

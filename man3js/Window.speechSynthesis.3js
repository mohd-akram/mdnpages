.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "WINDOW.SPEECHSYNTHESIS" "3JS" "June 7, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
Window.speechSynthesis \- Window: speechSynthesis property
.SH SYNOPSIS
The \f[CR]speechSynthesis\f[R] read\-only property of the Window object
returns a \f[CR]SpeechSynthesis\f[R] object, which is the entry point
into using Web Speech API speech synthesis functionality.
.SH VALUE
A \f[CR]SpeechSynthesis\f[R] object.
.SH EXAMPLES
In our basic \c
.UR https://github.com/mdn/dom-examples/tree/main/web-speech-api/speak-easy-synthesis
Speech synthesizer demo
.UE \c
, we first grab a reference to the SpeechSynthesis controller using
\f[CR]window.speechSynthesis\f[R].
After defining some necessary variables, we retrieve a list of the
voices available using \f[CR]SpeechSynthesis.getVoices()\f[R] and
populate a select menu with them so the user can choose what voice they
want.
.PP
Inside the \f[CR]inputForm.onsubmit\f[R] handler, we stop the form
submitting with preventDefault(), create a new
\f[CR]SpeechSynthesisUtterance\f[R] instance containing the text from
the text \f[CR]<input>\f[R], set the utterance\(cqs voice to the voice
selected in the \f[CR]<select>\f[R] element, and start the utterance
speaking via the \f[CR]SpeechSynthesis.speak()\f[R] method.
.IP
.EX
\f[B]const\f[R] synth = window.speechSynthesis;

\f[B]const\f[R] inputForm = document.querySelector(\(dqform\(dq);
\f[B]const\f[R] inputTxt = document.querySelector(\(dqinput\(dq);
\f[B]const\f[R] voiceSelect = document.querySelector(\(dqselect\(dq);

\f[B]function\f[R] populateVoiceList() {
  voices = synth.getVoices();

  \f[B]for\f[R] (\f[B]const\f[R] voice \f[B]of\f[R] voices) {
    \f[B]const\f[R] option = document.createElement(\(dqoption\(dq);
    option.textContent = \(ga${voice.name} (${voice.lang})\(ga;

    \f[B]if\f[R] (voice.default) {
      option.textContent += \(dq \(em DEFAULT\(dq;
    }

    option.setAttribute(\(dqdata\-lang\(dq, voice.lang);
    option.setAttribute(\(dqdata\-name\(dq, voice.name);
    voiceSelect.appendChild(option);
  }
}

populateVoiceList();
\f[B]if\f[R] (speechSynthesis.onvoiceschanged !== \f[B]undefined\f[R]) {
  speechSynthesis.onvoiceschanged = populateVoiceList;
}

inputForm.onsubmit = (event) \f[B]=>\f[R] {
  event.preventDefault();

  \f[B]const\f[R] utterThis = \f[B]new\f[R] SpeechSynthesisUtterance(inputTxt.value);
  \f[B]const\f[R] selectedOption =
    voiceSelect.selectedOptions[0].getAttribute(\(dqdata\-name\(dq);
  utterThis.voice = voices.find((v) \f[B]=>\f[R] v.name === selectedOption);
  synth.speak(utterThis);
  inputTxt.blur();
};
.EE
.SH SEE ALSO
.IP \(bu 2
Web Speech API

.\" Automatically generated by Pandoc 3.1.12.3
.\"
.TH "OfflineAudioContext.OfflineAudioContext" "JS" "November 28, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
OfflineAudioContext.OfflineAudioContext \- OfflineAudioContext:
OfflineAudioContext() constructor
.SH SYNOPSIS
The \f[B]\f[CB]OfflineAudioContext()\f[B]\f[R] constructor\[em]part of
the Web Audio API\[em]creates and returns a new
\f[CR]OfflineAudioContext\f[R] object instance, which can then be used
to render audio to an \f[CR]AudioBuffer\f[R] rather than to an audio
output device.
.SH SYNTAX
.IP
.EX
new OfflineAudioContext(options)

new OfflineAudioContext(numberOfChannels, length, sampleRate)
.EE
.SS Parameters
You can specify the parameters for the \f[CR]OfflineAudioContext()\f[R]
constructor as either the same set of parameters as are inputs into the
\f[CR]BaseAudioContext.createBuffer\f[R] method, or by passing those
parameters in an \f[CR]options\f[R] object.
Either way, the individual parameters are the same.
.TP
\f[B]numberOfChannels\f[R]
An integer specifying the number of channels the resulting
\f[CR]AudioBuffer\f[R] should have.
.TP
\f[B]length\f[R]
An integer specifying the size of the buffer to create for the audio
context, in sample\-frames, where one sample\-frame is a unit that can
contain a single sample of audio data for every channel in the audio
data.
For example, a 5\-second buffer with a \f[CR]sampleRate\f[R] of 48000Hz
would have a length of \f[CR]5 * 48000 = 240000\f[R] sample\-frames.
.TP
\f[B]sampleRate\f[R]
The sample\-rate of the linear audio data in sample\-frames per second.
All user agents are required to support a range of 8000Hz to 96000Hz,
and may support a wider range than that.
The most commonly\-used rate is 44100Hz, which is the sample rate used
by CD audio.
.PP
It is important to note that, whereas you can create a new
\f[CR]AudioContext\f[R] using the \f[CR]new AudioContext()\f[R]
constructor with no arguments, the \f[CR]OfflineAudioContext()\f[R]
constructor requires three arguments, since it needs to create an
\f[CR]AudioBuffer\f[R].
This works in exactly the same way as when you create a new
\f[CR]AudioBuffer\f[R] with the \f[CR]BaseAudioContext.createBuffer\f[R]
method.
For more detail, read Audio buffers: frames, samples and channels from
our Basic concepts guide.
.SS Return value
A new \f[CR]OfflineAudioContext\f[R] object whose associated
\f[CR]AudioBuffer\f[R] is configured as requested.
.PP
Like a regular \f[CR]AudioContext\f[R], an
\f[CR]OfflineAudioContext\f[R] can be the target of events, therefore it
implements the \f[CR]EventTarget\f[R] interface.
.SH EXAMPLES
.IP
.EX
\f[B]const\f[R] offlineCtx = \f[B]new\f[R] OfflineAudioContext({
  numberOfChannels: 2,
  length: 44100 * 40,
  sampleRate: 44100,
});
\f[B]const\f[R] source = offlineCtx.createBufferSource();
\f[I]// \&...\f[R]
.EE
.PP
For a full working example, see our \c
.UR https://mdn.github.io/webaudio-examples/offline-audio-context-promise/
offline\-audio\-context\-promise
.UE \c
\ GitHub repo (see the \c
.UR https://github.com/mdn/webaudio-examples/blob/main/offline-audio-context-promise/index.html
source code
.UE \c
\ too.)

.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "GPUDEVICE.CREATERENDERPIPELINEASYNC" "3JS" "June 18, 2025" "JavaScript" "JavaScript Reference Manual"
.SH NAME
GPUDevice.createRenderPipelineAsync \- GPUDevice:
createRenderPipelineAsync() method
.SH SYNOPSIS
\f[B]Secure context:\f[R] This feature is available only in secure
contexts (HTTPS).
.PP
\f[B]Note:\f[R] This feature is available in Web Workers.
.PP
The \f[B]\f[CB]createRenderPipelineAsync()\f[B]\f[R] method of the
\f[CR]GPUDevice\f[R] interface returns a \f[CR]Promise\f[R] that
fulfills with a \f[CR]GPURenderPipeline\f[R], which can control the
vertex and fragment shader stages and be used in a
\f[CR]GPURenderPassEncoder\f[R] or \f[CR]GPURenderBundleEncoder\f[R],
once the pipeline can be used without any stalling.
.RS
.PP
\f[B]Note:\f[R] It is generally preferable to use this method over
\f[CR]GPUDevice.createRenderPipeline()\f[R] whenever possible, as it
prevents blocking of GPU operation execution on pipeline compilation.
.RE
.SH SYNTAX
.IP
.EX
createRenderPipelineAsync(descriptor)
.EE
.SS Parameters
.TP
\f[B]descriptor\f[R]
See the descriptor definition for the
\f[CR]GPUDevice.createRenderPipeline()\f[R] method.
.SS Return value
A \f[CR]Promise\f[R] that fulfills with a \f[CR]GPURenderPipeline\f[R]
object instance when the created pipeline is ready to be used without
additional delay.
.SS Validation
If pipeline creation fails and the resulting pipeline becomes invalid as
a result, the returned promise rejects with a
\f[CR]GPUPipelineError\f[R]:
.IP \(bu 2
If this is due to an internal error, the \f[CR]GPUPipelineError\f[R]
will have a \f[CR]reason\f[R] of \f[CR]\(dqinternal\(dq\f[R].
.IP \(bu 2
If this is due to a validation error, the \f[CR]GPUPipelineError\f[R]
will have a \f[CR]reason\f[R] of \f[CR]\(dqvalidation\(dq\f[R].
.PP
A validation error can occur if any of the following are false:
.IP \(bu 2
For \f[CR]depthStencil\f[R] objects:
.RS 2
.IP \(bu 2
\f[CR]format\f[R] is a \c
.UR https://gpuweb.github.io/gpuweb/#depth-or-stencil-format
\f[CR]depth\-or\-stencil\f[R]
.UE \c
\ format.
.IP \(bu 2
The \f[CR]depthBias\f[R], \f[CR]depthBiasClamp\f[R], and
\f[CR]depthBiasSlopeScale\f[R] properties are set to 0 for line and
point topologies, i.e., if \f[CR]topology\f[R] is set to
\f[CR]\(dqline\-list\(dq\f[R], \f[CR]\(dqline\-strip\(dq\f[R], or
\f[CR]\(dqpoint\-list\(dq\f[R].
.IP \(bu 2
If \f[CR]depthWriteEnabled\f[R] is \f[CR]true\f[R] or
\f[CR]depthCompare\f[R] is not \f[CR]\(dqalways\(dq\f[R],
\f[CR]format\f[R] has a depth component.
.IP \(bu 2
If \f[CR]stencilFront\f[R] or \f[CR]stencilBack\f[R]\(cqs properties are
not at their default values, \f[CR]format\f[R] has a stencil component.
.RE
.IP \(bu 2
For \f[CR]fragment\f[R] objects:
.RS 2
.IP \(bu 2
\f[CR]targets.length\f[R] is less than or equal to the
\f[CR]GPUDevice\f[R]\(cqs \f[CR]maxColorAttachments\f[R] limit.
.IP \(bu 2
For each \f[CR]target\f[R], \f[CR]writeMask\f[R]\(cqs numeric equivalent
is less than 16.
.IP \(bu 2
If any of the used blend factor operations use the source alpha channel
(for example \f[CR]\(dqsrc\-alpha\-saturated\(dq\f[R]), the output has
an alpha channel (that is, it must be a \f[CR]vec4\f[R]).
.IP \(bu 2
If the \f[CR]entryPoint\f[R] property is omitted, the shader code
contains a single fragment shader entry point function for the browser
to use as the default entry point.
.RE
.IP \(bu 2
For \f[CR]primitive\f[R] objects:
.RS 2
.IP \(bu 2
If the \f[CR]unclippedDepth\f[R] property is used, the
\f[CR]depth\-clip\-control\f[R] feature is enabled.
.RE
.IP \(bu 2
For \f[CR]vertex\f[R] objects:
.RS 2
.IP \(bu 2
If the \f[CR]entryPoint\f[R] property is omitted, the shader code
contains a single vertex shader entry point function for the browser to
use as the default entry point.
.RE
.SH EXAMPLES
.RS
.PP
\f[B]Note:\f[R] The \c
.UR https://webgpu.github.io/webgpu-samples/
WebGPU samples
.UE \c
\ feature many more examples.
.RE
.SS Basic example
The following example shows a basic example of the construction of a
valid render pipeline descriptor object, which is then used to create a
\f[CR]GPURenderPipeline\f[R] via a
\f[CR]createRenderPipelineAsync()\f[R] call.
.IP
.EX
\f[B]async\f[R] \f[B]function\f[R] init() {
  \f[I]// \&...\f[R]

  \f[B]const\f[R] vertexBuffers = [
    {
      attributes: [
        {
          shaderLocation: 0, \f[I]// position\f[R]
          offset: 0,
          format: \(dqfloat32x4\(dq,
        },
        {
          shaderLocation: 1, \f[I]// color\f[R]
          offset: 16,
          format: \(dqfloat32x4\(dq,
        },
      ],
      arrayStride: 32,
      stepMode: \(dqvertex\(dq,
    },
  ];

  \f[B]const\f[R] pipelineDescriptor = {
    vertex: {
      module: shaderModule,
      entryPoint: \(dqvertex_main\(dq,
      buffers: vertexBuffers,
    },
    fragment: {
      module: shaderModule,
      entryPoint: \(dqfragment_main\(dq,
      targets: [
        {
          format: navigator.gpu.getPreferredCanvasFormat(),
        },
      ],
    },
    primitive: {
      topology: \(dqtriangle\-list\(dq,
    },
    layout: \(dqauto\(dq,
  };

  \f[B]const\f[R] renderPipeline =
    \f[B]await\f[R] device.createRenderPipelineAsync(pipelineDescriptor);

  \f[I]// \&...\f[R]
}
.EE
.SH SEE ALSO
.IP \(bu 2
The WebGPU API

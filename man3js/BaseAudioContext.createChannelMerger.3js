.\" Automatically generated by Pandoc 3.7.0.1
.\"
.TH "BASEAUDIOCONTEXT.CREATECHANNELMERGER" "3JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
BaseAudioContext.createChannelMerger \- BaseAudioContext:
createChannelMerger() method
.SH SYNOPSIS
The \f[CR]createChannelMerger()\f[R] method of the
\f[CR]BaseAudioContext\f[R] interface creates a
\f[CR]ChannelMergerNode\f[R], which combines channels from multiple
audio streams into a single audio stream.
.RS
.PP
\f[B]Note:\f[R] The \f[CR]ChannelMergerNode()\f[R] constructor is the
recommended way to create a \f[CR]ChannelMergerNode\f[R]; see Creating
an AudioNode.
.RE
.SH SYNTAX
.IP
.EX
createChannelMerger(numberOfInputs)
.EE
.SS Parameters
.TP
\f[B]numberOfInputs\f[R]
The number of channels in the input audio streams, which the output
stream will contain; the default is 6 if this parameter is not
specified.
.SS Return value
A \f[CR]ChannelMergerNode\f[R].
.SH EXAMPLES
The following example shows how you could separate a stereo track (say,
a piece of music), and process the left and right channel differently.
To use them, you need to use the second and third parameters of the
\f[CR]AudioNode.connect(AudioNode)\f[R] method, which allow you to
specify both the index of the channel to connect from and the index of
the channel to connect to.
.IP
.EX
\f[B]const\f[R] ac = \f[B]new\f[R] AudioContext();
ac.decodeAudioData(someStereoBuffer, (data) \f[B]=>\f[R] {
  \f[B]const\f[R] source = ac.createBufferSource();
  source.buffer = data;
  \f[B]const\f[R] splitter = ac.createChannelSplitter(2);
  source.connect(splitter);
  \f[B]const\f[R] merger = ac.createChannelMerger(2);

  \f[I]// Reduce the volume of the left channel only\f[R]
  \f[B]const\f[R] gainNode = ac.createGain();
  gainNode.gain.setValueAtTime(0.5, ac.currentTime);
  splitter.connect(gainNode, 0);

  \f[I]// Connect the splitter back to the second input of the merger: we\f[R]
  \f[I]// effectively swap the channels, here, reversing the stereo image.\f[R]
  gainNode.connect(merger, 0, 1);
  splitter.connect(merger, 1, 0);

  \f[B]const\f[R] dest = ac.createMediaStreamDestination();

  \f[I]// Because we have used a ChannelMergerNode, we now have a stereo\f[R]
  \f[I]// MediaStream we can use to pipe the Web Audio graph to WebRTC,\f[R]
  \f[I]// MediaRecorder, etc.\f[R]
  merger.connect(dest);
});
.EE
.SH SEE ALSO
.IP \(bu 2
Using the Web Audio API

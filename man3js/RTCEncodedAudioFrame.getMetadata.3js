.\" Automatically generated by Pandoc 3.4
.\"
.TH "RTCEncodedAudioFrame.getMetadata" "JS" "September 1, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
RTCEncodedAudioFrame.getMetadata \- RTCEncodedAudioFrame: getMetadata()
method
.SH SYNOPSIS
\f[B]Note:\f[R] This feature is available in Dedicated Web Workers.
.PP
The \f[B]\f[CB]getMetadata()\f[B]\f[R] method of the
\f[CR]RTCEncodedAudioFrame\f[R] interface returns an object containing
the metadata associated with the frame.
.PP
This includes information about the frame, including the audio encoding
used, the synchronization source and contributing sources, and the
sequence number (for incoming frames).
.SH SYNTAX
.IP
.EX
getMetadata()
.EE
.SS Parameters
None.
.SS Return value
An object with the following properties:
.TP
\f[B]synchronizationSource\f[R]
A positive integer value indicating synchronization source
(\[lq]ssrc\[rq]) of the stream of RTP packets that are described by this
frame.
A source might be something like a microphone, or a mixer application
that combines multiple sources.
All packets from the same source share the same time source and sequence
space, and so can be ordered relative to each other.
Note that two frames with the same value refer to the same source.
.TP
\f[B]payloadType\f[R]
A positive integer value in the range from 0 to 127 that describes the
format of the RTP payload.
The mappings of values to formats is defined in RFC3550, and more
specifically \c
.UR https://www.rfc-editor.org/rfc/rfc3551#section-6
Section 6: Payload Type Definitions
.UE \c
\ of RFC3551.
.TP
\f[B]contributingSources\f[R]
An \f[CR]Array\f[R] of sources (ssrc) that have contributed to the
frame.
Consider the case of a conferencing application that combines audio from
multiple users.
The \f[CR]synchronizationSource\f[R] would include the ssrc of the
application, while \f[CR]contributingSources\f[R] would include the ssrc
values of all the individual audio sources.
.TP
\f[B]sequenceNumber\f[R]
The sequence number of an incoming audio frame (not used for outgoing
frames) that can be used for reconstructing the original send\-order of
frames.
This is number between 0 and 32767.
Note that while numbers are allocated sequentially when sent, they will
overflow at 32767 and restart back at 0.
Therefore to compare two frame sequence numbers, in order to determine
whether one is assumed to be after another, you must use \c
.UR https://en.wikipedia.org/wiki/Serial_number_arithmetic
serial number arithmetic
.UE \c
\&.
.SH EXAMPLES
This example WebRTC encoded transform implementation shows how you might
get the frame metadata in a \f[CR]transform()\f[R] function and log it.
.IP
.EX
addEventListener(\[dq]rtctransform\[dq], (event) \f[B]=>\f[R] {
  \f[B]const\f[R] \f[B]async\f[R] transform = \f[B]new\f[R] TransformStream({
    \f[B]async\f[R] transform(encodedFrame, controller) {

      \f[I]// Get the metadata and log\f[R]
      \f[B]const\f[R] frameMetaData = encodedFrame.getMetadata();
      console.log(frameMetaData)

      \f[I]// Enqueue the frame without modifying\f[R]
      controller.enqueue(encodedFrame);
    },
  });
  event.transformer.readable
    .pipeThrough(transform)
    .pipeTo(event.transformer.writable);
});
.EE
.PP
The resulting object from a local microphone might look like the one
shown below.
Note that there are no contributing sources because there is just one
source, and no \f[CR]sequenceNumber\f[R] because this is an outgoing
frame.
.IP
.EX
{
  \[dq]payloadType\[dq]: 109,
  \[dq]synchronizationSource\[dq]: 1876443470
}
.EE
.SH SEE ALSO
.IP \[bu] 2
Using WebRTC Encoded Transforms

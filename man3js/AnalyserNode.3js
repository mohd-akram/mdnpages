'\" t
.\" Automatically generated by Pandoc 3.2.1
.\"
.TH "AnalyserNode" "JS" "July 30, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AnalyserNode \- AnalyserNode
.SH SYNOPSIS
The \f[B]\f[CB]AnalyserNode\f[B]\f[R] interface represents a node able
to provide real\-time frequency and time\-domain analysis information.
It is an \f[CR]AudioNode\f[R] that passes the audio stream unchanged
from the input to the output, but allows you to take the generated data,
process it, and create audio visualizations.
.PP
An \f[CR]AnalyserNode\f[R] has exactly one input and one output.
The node works even if the output is not connected.
[IMAGE: Without modifying the audio stream, the node allows to get the
frequency and time\-domain data associated to it, using a FFT.]
Without modifying the audio stream, the node allows to get the frequency
and time\-domain data associated to it, using a FFT.
.PP
.TS
tab(@);
l l.
T{
Number of inputs
T}@T{
\f[CR]1\f[R]
T}
T{
Number of outputs
T}@T{
\f[CR]1\f[R] (but may be left unconnected)
T}
T{
Channel count mode
T}@T{
\f[CR]\[dq]max\[dq]\f[R]
T}
T{
Channel count
T}@T{
\f[CR]2\f[R]
T}
T{
Channel interpretation
T}@T{
\f[CR]\[dq]speakers\[dq]\f[R]
T}
.TE
.SH CONSTRUCTOR
.TP
\f[B]AnalyserNode()\f[R]
Creates a new instance of an \f[CR]AnalyserNode\f[R] object.
.SH INSTANCE PROPERTIES
\f[I]Inherits properties from its parent, \f[CI]AudioNode\f[I]\f[R].
.TP
\f[B]AnalyserNode.fftSize\f[R]
An unsigned long value representing the size of the FFT (\c
.UR https://en.wikipedia.org/wiki/Fast_Fourier_transform
Fast Fourier Transform
.UE \c
) to be used to determine the frequency domain.
.TP
\f[B]AnalyserNode.frequencyBinCount\f[R] \f[I](read\-only)\f[R]
An unsigned long value half that of the FFT size.
This generally equates to the number of data values you will have to
play with for the visualization.
.TP
\f[B]AnalyserNode.minDecibels\f[R]
A double value representing the minimum power value in the scaling range
for the FFT analysis data, for conversion to unsigned byte values \[em]
basically, this specifies the minimum value for the range of results
when using \f[CR]getByteFrequencyData()\f[R].
.TP
\f[B]AnalyserNode.maxDecibels\f[R]
A double value representing the maximum power value in the scaling range
for the FFT analysis data, for conversion to unsigned byte values \[em]
basically, this specifies the maximum value for the range of results
when using \f[CR]getByteFrequencyData()\f[R].
.TP
\f[B]AnalyserNode.smoothingTimeConstant\f[R]
A double value representing the averaging constant with the last
analysis frame \[em] basically, it makes the transition between values
over time smoother.
.SH INSTANCE METHODS
\f[I]Inherits methods from its parent, \f[CI]AudioNode\f[I]\f[R].
.TP
\f[B]AnalyserNode.getFloatFrequencyData()\f[R]
Copies the current frequency data into a \f[CR]Float32Array\f[R] array
passed into it.
.TP
\f[B]AnalyserNode.getByteFrequencyData()\f[R]
Copies the current frequency data into a \f[CR]Uint8Array\f[R] (unsigned
byte array) passed into it.
.TP
\f[B]AnalyserNode.getFloatTimeDomainData()\f[R]
Copies the current waveform, or time\-domain, data into a
\f[CR]Float32Array\f[R] array passed into it.
.TP
\f[B]AnalyserNode.getByteTimeDomainData()\f[R]
Copies the current waveform, or time\-domain, data into a
\f[CR]Uint8Array\f[R] (unsigned byte array) passed into it.
.SH EXAMPLES
.RS
.PP
\f[B]Note:\f[R] See the guide Visualizations with Web Audio API for more
information on creating audio visualizations.
.RE
.SS Basic usage
The following example shows basic usage of an \f[CR]AudioContext\f[R] to
create an \f[CR]AnalyserNode\f[R], then \f[CR]requestAnimationFrame\f[R]
and \f[CR]<canvas>\f[R] to collect time domain data repeatedly and draw
an \[lq]oscilloscope style\[rq] output of the current audio input.
For more complete applied examples/information, check out our \c
.UR https://mdn.github.io/webaudio-examples/voice-change-o-matic/
Voice\-change\-O\-matic
.UE \c
\ demo (see \c
.UR https://github.com/mdn/webaudio-examples/blob/main/voice-change-o-matic/scripts/app.js#L108-L193
app.js lines 108\-193
.UE \c
\ for relevant code).
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();

\f[I]// \&...\f[R]

\f[B]const\f[R] analyser = audioCtx.createAnalyser();
analyser.fftSize = 2048;

\f[B]const\f[R] bufferLength = analyser.frequencyBinCount;
\f[B]const\f[R] dataArray = \f[B]new\f[R] Uint8Array(bufferLength);
analyser.getByteTimeDomainData(dataArray);

\f[I]// Connect the source to be analysed\f[R]
source.connect(analyser);

\f[I]// Get a canvas defined with ID \[dq]oscilloscope\[dq]\f[R]
\f[B]const\f[R] canvas = document.getElementById(\[dq]oscilloscope\[dq]);
\f[B]const\f[R] canvasCtx = canvas.getContext(\[dq]2d\[dq]);

\f[I]// draw an oscilloscope of the current audio source\f[R]

\f[B]function\f[R] draw() {
  requestAnimationFrame(draw);

  analyser.getByteTimeDomainData(dataArray);

  canvasCtx.fillStyle = \[dq]rgb(200 200 200)\[dq];
  canvasCtx.fillRect(0, 0, canvas.width, canvas.height);

  canvasCtx.lineWidth = 2;
  canvasCtx.strokeStyle = \[dq]rgb(0 0 0)\[dq];

  canvasCtx.beginPath();

  \f[B]const\f[R] sliceWidth = (canvas.width * 1.0) / bufferLength;
  \f[B]let\f[R] x = 0;

  \f[B]for\f[R] (\f[B]let\f[R] i = 0; i < bufferLength; i++) {
    \f[B]const\f[R] v = dataArray[i] / 128.0;
    \f[B]const\f[R] y = (v * canvas.height) / 2;

    \f[B]if\f[R] (i === 0) {
      canvasCtx.moveTo(x, y);
    } \f[B]else\f[R] {
      canvasCtx.lineTo(x, y);
    }

    x += sliceWidth;
  }

  canvasCtx.lineTo(canvas.width, canvas.height / 2);
  canvasCtx.stroke();
}

draw();
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

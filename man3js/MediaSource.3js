.\" Automatically generated by Pandoc 3.1.11
.\"
.TH "MediaSource" "JS" "August 25, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
MediaSource \- MediaSource
.SH SYNOPSIS
The \f[B]\f[CB]MediaSource\f[B]\f[R] interface of the Media Source
Extensions API represents a source of media data for an
\f[CR]HTMLMediaElement\f[R] object.
A \f[CR]MediaSource\f[R] object can be attached to a
\f[CR]HTMLMediaElement\f[R] to be played in the user agent.
.SH CONSTRUCTOR
.TP
\f[B]MediaSource()\f[R]
Constructs and returns a new \f[CR]MediaSource\f[R] object with no
associated source buffers.
.SH INSTANCE PROPERTIES
.TP
\f[B]MediaSource.activeSourceBuffers\f[R] \f[I](read\-only)\f[R]
Returns a \f[CR]SourceBufferList\f[R] object containing a subset of the
\f[CR]SourceBuffer\f[R] objects contained within
\f[CR]MediaSource.sourceBuffers\f[R] \[em] the list of objects providing
the selected video track, enabled audio tracks, and shown/hidden text
tracks.
.TP
\f[B]MediaSource.duration\f[R]
Gets and sets the duration of the current media being presented.
.TP
\f[B]MediaSource.handle\f[R] \f[I](read\-only)\f[R] \f[I](experimental)\f[R]
Inside a dedicated worker, returns a \f[CR]MediaSourceHandle\f[R]
object, a proxy for the \f[CR]MediaSource\f[R] that can be transferred
from the worker back to the main thread and attached to a media element
via its \f[CR]HTMLMediaElement.srcObject\f[R] property.
.TP
\f[B]MediaSource.readyState\f[R] \f[I](read\-only)\f[R]
Returns an enum representing the state of the current
\f[CR]MediaSource\f[R], whether it is not currently attached to a media
element (\f[CR]closed\f[R]), attached and ready to receive
\f[CR]SourceBuffer\f[R] objects (\f[CR]open\f[R]), or attached but the
stream has been ended via \f[CR]MediaSource.endOfStream()\f[R]
(\f[CR]ended\f[R].)
.TP
\f[B]MediaSource.sourceBuffers\f[R] \f[I](read\-only)\f[R]
Returns a \f[CR]SourceBufferList\f[R] object containing the list of
\f[CR]SourceBuffer\f[R] objects associated with this
\f[CR]MediaSource\f[R].
.SH STATIC PROPERTIES
.TP
\f[B]MediaSource.canConstructInDedicatedWorker\f[R] \f[I](read\-only)\f[R] \f[I](experimental)\f[R]
A boolean; returns \f[CR]true\f[R] if \f[CR]MediaSource\f[R] worker
support is implemented, providing a low\-latency feature detection
mechanism.
.SH INSTANCE METHODS
\f[I]Inherits methods from its parent interface,
\f[CI]EventTarget\f[I].\f[R]
.TP
\f[B]MediaSource.addSourceBuffer()\f[R]
Creates a new \f[CR]SourceBuffer\f[R] of the given MIME type and adds it
to the \f[CR]MediaSource.sourceBuffers\f[R] list.
.TP
\f[B]MediaSource.clearLiveSeekableRange()\f[R]
Clears a seekable range previously set with a call to
\f[CR]setLiveSeekableRange()\f[R].
.TP
\f[B]MediaSource.endOfStream()\f[R]
Signals the end of the stream.
.TP
\f[B]MediaSource.removeSourceBuffer()\f[R]
Removes the given \f[CR]SourceBuffer\f[R] from the
\f[CR]MediaSource.sourceBuffers\f[R] list.
.TP
\f[B]MediaSource.setLiveSeekableRange()\f[R]
Sets the range that the user can seek to in the media element.
.SH STATIC METHODS
.TP
\f[B]MediaSource.isTypeSupported()\f[R]
Returns a boolean value indicating if the given MIME type is supported
by the current user agent \[em] this is, if it can successfully create
\f[CR]SourceBuffer\f[R] objects for that MIME type.
.SH EVENTS
.TP
\f[B]sourceclose\f[R]
Fired when the \f[CR]MediaSource\f[R] instance is not attached to a
media element anymore.
.TP
\f[B]sourceended\f[R]
Fired when the \f[CR]MediaSource\f[R] instance is still attached to a
media element, but \f[CR]endOfStream()\f[R] has been called.
.TP
\f[B]sourceopen\f[R]
Fired when the \f[CR]MediaSource\f[R] instance has been opened by a
media element and is ready for data to be appended to the
\f[CR]SourceBuffer\f[R] objects in \f[CR]sourceBuffers\f[R].
.SH EXAMPLES
.SS Complete basic example
The following simple example loads a video with
\f[CR]XMLHttpRequest\f[R], playing it as soon as it can.
This example was written by Nick Desaulniers and can be \c
.UR https://nickdesaulniers.github.io/netfix/demo/bufferAll.html
viewed live here
.UE \c
\ (you can also \c
.UR
https://github.com/nickdesaulniers/netfix/blob/gh-pages/demo/bufferAll.html
download the source
.UE \c
\ for further investigation).
The function \f[CR]getMediaSource()\f[R], which is not defined here,
returns a \f[CR]MediaSource\f[R].
.IP
.EX
const video = document.querySelector(\[dq]video\[dq]);

const assetURL = \[dq]frag_bunny.mp4\[dq];
// Need to be specific for Blink regarding codecs
// ./mp4info frag_bunny.mp4 | grep Codec
const mimeCodec = \[aq]video/mp4; codecs=\[dq]avc1.42E01E, mp4a.40.2\[dq]\[aq];
let mediaSource;

if (\[dq]MediaSource\[dq] in window && MediaSource.isTypeSupported(mimeCodec)) {
  mediaSource = getMediaSource();
  console.log(mediaSource.readyState); // closed
  video.src = URL.createObjectURL(mediaSource);
  mediaSource.addEventListener(\[dq]sourceopen\[dq], sourceOpen);
} else {
  console.error(\[dq]Unsupported MIME type or codec: \[dq], mimeCodec);
}

function sourceOpen() {
  console.log(this.readyState); // open
  const sourceBuffer = mediaSource.addSourceBuffer(mimeCodec);
  fetchAB(assetURL, (buf) => {
    sourceBuffer.addEventListener(\[dq]updateend\[dq], () => {
      mediaSource.endOfStream();
      video.play();
      console.log(mediaSource.readyState); // ended
    });
    sourceBuffer.appendBuffer(buf);
  });
}

function fetchAB(url, cb) {
  console.log(url);
  const xhr = new XMLHttpRequest();
  xhr.open(\[dq]get\[dq], url);
  xhr.responseType = \[dq]arraybuffer\[dq];
  xhr.onload = () => {
    cb(xhr.response);
  };
  xhr.send();
}
.EE
.SS Constructing a \f[CR]MediaSource\f[R] in a dedicated worker and passing it to the main thread
The \f[CR]handle\f[R] property can be accessed inside a dedicated worker
and the resulting \f[CR]MediaSourceHandle\f[R] object is then
transferred over to the thread that created the worker (in this case the
main thread) via a \f[CR]postMessage()\f[R] call:
.IP
.EX
// Inside dedicated worker
let mediaSource = new MediaSource();
let handle = mediaSource.handle;
// Transfer the handle to the context that created the worker
postMessage({ arg: handle }, [handle]);

mediaSource.addEventListener(\[dq]sourceopen\[dq], () => {
  // Await sourceopen on MediaSource before creating SourceBuffers
  // and populating them with fetched media \[em] MediaSource won\[aq]t
  // accept creation of SourceBuffers until it is attached to the
  // HTMLMediaElement and its readyState is \[dq]open\[dq]
});
.EE
.PP
Over in the main thread, we receive the handle via a \f[CR]message\f[R]
event handler, attach it to a \f[CR]<video>\f[R] via its
\f[CR]HTMLMediaElement.srcObject\f[R] property, and \f[CR]play\f[R] the
video:
.IP
.EX
worker.addEventListener(\[dq]message\[dq], (msg) => {
  let mediaSourceHandle = msg.data.arg;
  video.srcObject = mediaSourceHandle;
  video.play();
});
.EE
.RS
.PP
\f[B]Note:\f[R] \f[CR]MediaSourceHandle\f[R]s cannot be successfully
transferred into or via a shared worker or service worker.
.RE
.SH SEE ALSO
.IP \[bu] 2
\f[CR]SourceBuffer\f[R]
.IP \[bu] 2
\f[CR]SourceBufferList\f[R]

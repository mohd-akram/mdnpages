.\" Automatically generated by Pandoc 3.6.2
.\"
.TH "BaseAudioContext.createBufferSource" "JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
BaseAudioContext.createBufferSource \- BaseAudioContext:
createBufferSource() method
.SH SYNOPSIS
The \f[CR]createBufferSource()\f[R] method of the
\f[CR]BaseAudioContext\f[R] Interface is used to create a new
\f[CR]AudioBufferSourceNode\f[R], which can be used to play audio data
contained within an \f[CR]AudioBuffer\f[R] object.
\f[CR]AudioBuffer\f[R]s are created using
\f[CR]BaseAudioContext.createBuffer\f[R] or returned by
\f[CR]BaseAudioContext.decodeAudioData\f[R] when it successfully decodes
an audio track.
.RS
.PP
\f[B]Note:\f[R] The \f[CR]AudioBufferSourceNode()\f[R] constructor is
the recommended way to create a \f[CR]AudioBufferSourceNode\f[R]; see
Creating an AudioNode.
.RE
.SH SYNTAX
.IP
.EX
createBufferSource()
.EE
.SS Parameters
None.
.SS Return value
An \f[CR]AudioBufferSourceNode\f[R].
.SH EXAMPLES
In this example, we create a two second buffer, fill it with white
noise, and then play it via an \f[CR]AudioBufferSourceNode\f[R].
The comments should clearly explain what is going on.
.RS
.PP
\f[B]Note:\f[R] You can also \c
.UR https://mdn.github.io/webaudio-examples/audio-buffer/
run the code live
.UE \c
, or \c
.UR https://github.com/mdn/webaudio-examples/blob/main/audio-buffer/index.html
view the source
.UE \c
\&.
.RE
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();
\f[B]const\f[R] button = document.querySelector(\[dq]button\[dq]);
\f[B]const\f[R] pre = document.querySelector(\[dq]pre\[dq]);
\f[B]const\f[R] myScript = document.querySelector(\[dq]script\[dq]);

pre.textContent = myScript.textContent;

\f[I]// Stereo\f[R]
\f[B]const\f[R] channels = 2;
\f[I]// Create an empty two second stereo buffer at the\f[R]
\f[I]// sample rate of the AudioContext\f[R]
\f[B]const\f[R] frameCount = audioCtx.sampleRate * 2.0;

\f[B]const\f[R] myArrayBuffer = audioCtx.createBuffer(
  channels,
  frameCount,
  audioCtx.sampleRate,
);

button.onclick = () \f[B]=>\f[R] {
  \f[I]// Fill the buffer with white noise;\f[R]
  \f[I]//just random values between \-1.0 and 1.0\f[R]
  \f[B]for\f[R] (\f[B]let\f[R] channel = 0; channel < channels; channel++) {
    \f[I]// This gives us the actual ArrayBuffer that contains the data\f[R]
    \f[B]const\f[R] nowBuffering = myArrayBuffer.getChannelData(channel);
    \f[B]for\f[R] (\f[B]let\f[R] i = 0; i < frameCount; i++) {
      \f[I]// Math.random() is in [0; 1.0]\f[R]
      \f[I]// audio needs to be in [\-1.0; 1.0]\f[R]
      nowBuffering[i] = Math.random() * 2 \- 1;
    }
  }

  \f[I]// Get an AudioBufferSourceNode.\f[R]
  \f[I]// This is the AudioNode to use when we want to play an AudioBuffer\f[R]
  \f[B]const\f[R] source = audioCtx.createBufferSource();
  \f[I]// set the buffer in the AudioBufferSourceNode\f[R]
  source.buffer = myArrayBuffer;
  \f[I]// connect the AudioBufferSourceNode to the\f[R]
  \f[I]// destination so we can hear the sound\f[R]
  source.connect(audioCtx.destination);
  \f[I]// start the source playing\f[R]
  source.start();
};
.EE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

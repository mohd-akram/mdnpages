.\" Automatically generated by Pandoc 3.2.1
.\"
.TH "AudioContext.createMediaStreamSource" "JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioContext.createMediaStreamSource \- AudioContext:
createMediaStreamSource() method
.SH SYNOPSIS
The \f[CR]createMediaStreamSource()\f[R] method of the
\f[CR]AudioContext\f[R] Interface is used to create a new
\f[CR]MediaStreamAudioSourceNode\f[R] object, given a media stream (say,
from a \f[CR]MediaDevices.getUserMedia\f[R] instance), the audio from
which can then be played and manipulated.
.PP
For more details about media stream audio source nodes, check out the
\f[CR]MediaStreamAudioSourceNode\f[R] reference page.
.SH SYNTAX
.IP
.EX
createMediaStreamSource(stream)
.EE
.SS Parameters
.TP
\f[B]stream\f[R]
A \f[CR]MediaStream\f[R] to serve as an audio source to be fed into an
audio processing graph for use and manipulation.
.SS Return value
A new \f[CR]MediaStreamAudioSourceNode\f[R] object representing the
audio node whose media is obtained from the specified source stream.
.SH EXAMPLES
In this example, we grab a media (audio + video) stream from
\f[CR]navigator.getUserMedia\f[R], feed the media into a
\f[CR]<video>\f[R] element to play then mute the audio, but then also
feed the audio into a \f[CR]MediaStreamAudioSourceNode\f[R].
Next, we feed this source audio into a low pass
\f[CR]BiquadFilterNode\f[R] (which effectively serves as a bass
booster), then a \f[CR]AudioDestinationNode\f[R].
.PP
The range slider below the \f[CR]<video>\f[R] element controls the
amount of gain given to the lowpass filter \[em] increase the value of
the slider to make the audio sound more bass heavy!
.RS
.PP
\f[B]Note:\f[R] You can see this \c
.UR https://mdn.github.io/webaudio-examples/stream-source-buffer/
example running live
.UE \c
, or \c
.UR https://github.com/mdn/webaudio-examples/tree/main/stream-source-buffer
view the source
.UE \c
\&.
.RE
.IP
.EX
\f[B]const\f[R] pre = document.querySelector(\[dq]pre\[dq]);
\f[B]const\f[R] video = document.querySelector(\[dq]video\[dq]);
\f[B]const\f[R] myScript = document.querySelector(\[dq]script\[dq]);
\f[B]const\f[R] range = document.querySelector(\[dq]input\[dq]);

\f[I]// getUserMedia block \- grab stream\f[R]
\f[I]// put it into a MediaStreamAudioSourceNode\f[R]
\f[I]// also output the visuals into a video element\f[R]

\f[B]if\f[R] (navigator.mediaDevices) {
  console.log(\[dq]getUserMedia supported.\[dq]);
  navigator.mediaDevices
    .getUserMedia({ audio: \f[B]true\f[R], video: \f[B]true\f[R] })
    .then((stream) \f[B]=>\f[R] {
      video.srcObject = stream;
      video.onloadedmetadata = (e) \f[B]=>\f[R] {
        video.play();
        video.muted = \f[B]true\f[R];
      };

      \f[I]// Create a MediaStreamAudioSourceNode\f[R]
      \f[I]// Feed the HTMLMediaElement into it\f[R]
      \f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();
      \f[B]const\f[R] source = audioCtx.createMediaStreamSource(stream);

      \f[I]// Create a biquadfilter\f[R]
      \f[B]const\f[R] biquadFilter = audioCtx.createBiquadFilter();
      biquadFilter.type = \[dq]lowshelf\[dq];
      biquadFilter.frequency.value = 1000;
      biquadFilter.gain.value = range.value;

      \f[I]// connect the AudioBufferSourceNode to the gainNode\f[R]
      \f[I]// and the gainNode to the destination, so we can play the\f[R]
      \f[I]// music and adjust the volume using the mouse cursor\f[R]
      source.connect(biquadFilter);
      biquadFilter.connect(audioCtx.destination);

      \f[I]// Get new mouse pointer coordinates when mouse is moved\f[R]
      \f[I]// then set new gain value\f[R]

      range.oninput = () \f[B]=>\f[R] {
        biquadFilter.gain.value = range.value;
      };
    })
    .catch((err) \f[B]=>\f[R] {
      console.log(\[ga]The following gUM error occurred: ${err}\[ga]);
    });
} \f[B]else\f[R] {
  console.log(\[dq]getUserMedia not supported on your browser!\[dq]);
}

\f[I]// dump script to pre element\f[R]

pre.textContent = myScript.textContent;
.EE
.RS
.PP
\f[B]Note:\f[R] As a consequence of calling
\f[CR]createMediaStreamSource()\f[R], audio playback from the media
stream will be re\-routed into the processing graph of the
\f[CR]AudioContext\f[R].
So playing/pausing the stream can still be done through the media
element API and the player controls.
.RE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API

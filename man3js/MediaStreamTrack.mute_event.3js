.\" Automatically generated by Pandoc 3.1.12.3
.\"
.TH "MediaStreamTrack.mute_event" "JS" "July 7, 2023" "JavaScript" "JavaScript Reference Manual"
.SH NAME
MediaStreamTrack.mute_event \- MediaStreamTrack: mute event
.SH SYNOPSIS
The \f[B]\f[CB]mute\f[B]\f[R] event is sent to a
\f[CR]MediaStreamTrack\f[R] when the track\[cq]s source is temporarily
unable to provide media data.
.PP
When the track is once again able to produce media output, an
\f[CR]unmute\f[R] event is sent.
.PP
During the time between the \f[CR]mute\f[R] event and the
\f[CR]unmute\f[R] event, the value of the track\[cq]s \f[CR]muted\f[R]
property is \f[CR]true\f[R].
.RS
.PP
\f[B]Note:\f[R] The condition that most people think of as
\[lq]muted\[rq] (that is, a user\-toggled state of silencing a track) is
actually managed using the \f[CR]MediaStreamTrack.enabled\f[R] property,
for which there are no events.
.RE
.PP
This event is not cancelable and does not bubble.
.SH SYNTAX
Use the event name in methods like \f[CR]addEventListener()\f[R], or set
an event handler property.
.IP
.EX
addEventListener(\[dq]mute\[dq], (event) \f[B]=>\f[R] {});

onmute = (event) \f[B]=>\f[R] {};
.EE
.SH EVENT TYPE
A generic \f[CR]Event\f[R].
.SH EXAMPLES
In this example, event handlers are established for the \f[CR]mute\f[R]
and \f[CR]unmute\f[R] events in order to detect when the media is not
flowing from the source for the \f[CR]MediaStreamTrack\f[R] referenced
by \f[CR]musicTrack\f[R].
.IP
.EX
musicTrack.addEventListener(
  \[dq]mute\[dq],
  (event) \f[B]=>\f[R] {
    document.getElementById(\[dq]timeline\-widget\[dq]).style.backgroundColor = \[dq]#aaa\[dq];
  },
  \f[B]false\f[R],
);

musicTrack.addEventListener(
  \[dq]unmute\[dq],
  (event) \f[B]=>\f[R] {
    document.getElementById(\[dq]timeline\-widget\[dq]).style.backgroundColor = \[dq]#fff\[dq];
  },
  \f[B]false\f[R],
);
.EE
.PP
With these event handlers in place, when the track \f[CR]musicTrack\f[R]
enters its \f[CR]muted\f[R] state, the element with the ID
\f[CR]timeline\-widget\f[R] gets its background color changed to
\f[CR]#aaa\f[R].
When the track exits the muted state\[em]detected by the arrival of an
\f[CR]unmute\f[R] event\[em]the background color is restored to white.
.PP
You can also use the \f[CR]onmute\f[R] event handler property to set up
a handler for this event; similarly, the \f[CR]onunmute\f[R] event
handler is available for setting up a handler for the \f[CR]unmute\f[R]
event.
The following example shows this:
.IP
.EX
musicTrack.onmute = (event) \f[B]=>\f[R] {
  document.getElementById(\[dq]timeline\-widget\[dq]).style.backgroundColor = \[dq]#aaa\[dq];
};

musicTrack.onunmute = (event) \f[B]=>\f[R] {
  document.getElementById(\[dq]timeline\-widget\[dq]).style.backgroundColor = \[dq]#fff\[dq];
};
.EE
.SS Mute tracks through receivers
The following example shows how to mute tracks using receivers.
.IP
.EX
\f[I]// Peer 1 (Receiver)\f[R]
audioTrack.addEventListener(\[dq]mute\[dq], (event) \f[B]=>\f[R] {
  \f[I]// Do something in UI\f[R]
});

videoTrack.addEventListener(\[dq]mute\[dq], (event) \f[B]=>\f[R] {
  \f[I]// Do something in UI\f[R]
});

\f[I]// Peer 2 (Sender)\f[R]
\f[B]const\f[R] transceivers = peer.getTransceivers();

\f[B]const\f[R] audioTrack = transceivers[0];
audioTrack.direction = \[dq]recvonly\[dq];

\f[B]const\f[R] videoTrack = transceivers[1];
videoTrack.direction = \[dq]recvonly\[dq];
.EE
.PP
\f[CR]transceivers\f[R] is an array of \f[CR]RTCRtpTransceiver\f[R]
where you can find the audio or video track sent and received.
For more information, see the \f[CR]direction\f[R] article.
.SH SEE ALSO
.IP \[bu] 2
\f[CR]unmute\f[R] event
.IP \[bu] 2
\f[CR]direction\f[R]

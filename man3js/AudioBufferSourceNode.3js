'\" t
.\" Automatically generated by Pandoc 3.6.2
.\"
.TH "AudioBufferSourceNode" "JS" "July 26, 2024" "JavaScript" "JavaScript Reference Manual"
.SH NAME
AudioBufferSourceNode \- AudioBufferSourceNode
.SH SYNOPSIS
The \f[B]\f[CB]AudioBufferSourceNode\f[B]\f[R] interface is an
\f[CR]AudioScheduledSourceNode\f[R] which represents an audio source
consisting of in\-memory audio data, stored in an
\f[CR]AudioBuffer\f[R].
.PP
This interface is especially useful for playing back audio which has
particularly stringent timing accuracy requirements, such as for sounds
that must match a specific rhythm and can be kept in memory rather than
being played from disk or the network.
To play sounds which require accurate timing but must be streamed from
the network or played from disk, use a \f[CR]AudioWorkletNode\f[R] to
implement its playback.
.PP
An \f[CR]AudioBufferSourceNode\f[R] has no inputs and exactly one
output, which has the same number of channels as the
\f[CR]AudioBuffer\f[R] indicated by its \f[CR]buffer\f[R] property.
If there\[cq]s no buffer set\[em]that is, if \f[CR]buffer\f[R] is
\f[CR]null\f[R]\[em]the output contains a single channel of silence
(every sample is 0).
.PP
An \f[CR]AudioBufferSourceNode\f[R] can only be played once; after each
call to \f[CR]start()\f[R], you have to create a new node if you want to
play the same sound again.
Fortunately, these nodes are very inexpensive to create, and the actual
\f[CR]AudioBuffer\f[R]s can be reused for multiple plays of the sound.
Indeed, you can use these nodes in a \[lq]fire and forget\[rq] manner:
create the node, call \f[CR]start()\f[R] to begin playing the sound, and
don\[cq]t even bother to hold a reference to it.
It will automatically be garbage\-collected at an appropriate time,
which won\[cq]t be until sometime after the sound has finished playing.
.PP
Multiple calls to \f[CR]stop()\f[R] are allowed.
The most recent call replaces the previous one, if the
\f[CR]AudioBufferSourceNode\f[R] has not already reached the end of the
buffer.
[IMAGE: The AudioBufferSourceNode takes the content of an AudioBuffer
and m]
The AudioBufferSourceNode takes the content of an AudioBuffer and m
.PP
.TS
tab(@);
l l.
T{
Number of inputs
T}@T{
\f[CR]0\f[R]
T}
T{
Number of outputs
T}@T{
\f[CR]1\f[R]
T}
T{
Channel count
T}@T{
defined by the associated \[ga]AudioBuffer\[ga]
T}
.TE
.SH CONSTRUCTOR
.TP
\f[B]AudioBufferSourceNode()\f[R]
Creates and returns a new \f[CR]AudioBufferSourceNode\f[R] object.
As an alternative, you can use the
\f[CR]BaseAudioContext.createBufferSource()\f[R] factory method; see
Creating an AudioNode.
.SH INSTANCE PROPERTIES
\f[I]Inherits properties from its parent,
\f[CI]AudioScheduledSourceNode\f[I]\f[R].
.TP
\f[B]AudioBufferSourceNode.buffer\f[R]
An \f[CR]AudioBuffer\f[R] that defines the audio asset to be played, or
when set to the value \f[CR]null\f[R], defines a single channel of
silence (in which every sample is 0.0).
.TP
\f[B]AudioBufferSourceNode.detune\f[R]
A k\-rate \f[CR]AudioParam\f[R] representing detuning of playback in \c
.UR https://en.wikipedia.org/wiki/Cent_%28music%29
cents
.UE \c
\&.
This value is compounded with \f[CR]playbackRate\f[R] to determine the
speed at which the sound is played.
Its default value is \f[CR]0\f[R] (meaning no detuning), and its nominal
range is \-∞ to ∞.
.TP
\f[B]AudioBufferSourceNode.loop\f[R]
A Boolean attribute indicating if the audio asset must be replayed when
the end of the \f[CR]AudioBuffer\f[R] is reached.
Its default value is \f[CR]false\f[R].
.TP
\f[B]AudioBufferSourceNode.loopStart\f[R] \f[I](optional)\f[R]
A floating\-point value indicating the time, in seconds, at which
playback of the \f[CR]AudioBuffer\f[R] must begin when \f[CR]loop\f[R]
is \f[CR]true\f[R].
Its default value is \f[CR]0\f[R] (meaning that at the beginning of each
loop, playback begins at the start of the audio buffer).
.TP
\f[B]AudioBufferSourceNode.loopEnd\f[R] \f[I](optional)\f[R]
A floating\-point number indicating the time, in seconds, at which
playback of the \f[CR]AudioBuffer\f[R] stops and loops back to the time
indicated by \f[CR]loopStart\f[R], if \f[CR]loop\f[R] is
\f[CR]true\f[R].
The default value is \f[CR]0\f[R].
.TP
\f[B]AudioBufferSourceNode.playbackRate\f[R]
A k\-rate \f[CR]AudioParam\f[R] that defines the speed factor at which
the audio asset will be played, where a value of 1.0 is the sound\[cq]s
natural sampling rate.
Since no pitch correction is applied on the output, this can be used to
change the pitch of the sample.
This value is compounded with \f[CR]detune\f[R] to determine the final
playback rate.
.SH INSTANCE METHODS
\f[I]Inherits methods from its parent,
\f[CI]AudioScheduledSourceNode\f[I], and overrides the following
method:\f[R].
.TP
\f[B]start()\f[R]
Schedules playback of the audio data contained in the buffer, or begins
playback immediately.
Additionally allows the start offset and play duration to be set.
.SH EXAMPLES
In this example, we create a two\-second buffer, fill it with white
noise, and then play it using an \f[CR]AudioBufferSourceNode\f[R].
The comments should clearly explain what is going on.
.RS
.PP
\f[B]Note:\f[R] You can also \c
.UR https://mdn.github.io/webaudio-examples/audio-buffer/
run the code live
.UE \c
, or \c
.UR https://github.com/mdn/webaudio-examples/blob/main/audio-buffer/index.html
view the source
.UE \c
\&.
.RE
.IP
.EX
\f[B]const\f[R] audioCtx = \f[B]new\f[R] AudioContext();

\f[I]// Create an empty three\-second stereo buffer at the sample rate of the AudioContext\f[R]
\f[B]const\f[R] myArrayBuffer = audioCtx.createBuffer(
  2,
  audioCtx.sampleRate * 3,
  audioCtx.sampleRate,
);

\f[I]// Fill the buffer with white noise;\f[R]
\f[I]//just random values between \-1.0 and 1.0\f[R]
\f[B]for\f[R] (\f[B]let\f[R] channel = 0; channel < myArrayBuffer.numberOfChannels; channel++) {
  \f[I]// This gives us the actual ArrayBuffer that contains the data\f[R]
  \f[B]const\f[R] nowBuffering = myArrayBuffer.getChannelData(channel);
  \f[B]for\f[R] (\f[B]let\f[R] i = 0; i < myArrayBuffer.length; i++) {
    \f[I]// Math.random() is in [0; 1.0]\f[R]
    \f[I]// audio needs to be in [\-1.0; 1.0]\f[R]
    nowBuffering[i] = Math.random() * 2 \- 1;
  }
}

\f[I]// Get an AudioBufferSourceNode.\f[R]
\f[I]// This is the AudioNode to use when we want to play an AudioBuffer\f[R]
\f[B]const\f[R] source = audioCtx.createBufferSource();
\f[I]// set the buffer in the AudioBufferSourceNode\f[R]
source.buffer = myArrayBuffer;
\f[I]// connect the AudioBufferSourceNode to the\f[R]
\f[I]// destination so we can hear the sound\f[R]
source.connect(audioCtx.destination);
\f[I]// start the source playing\f[R]
source.start();
.EE
.RS
.PP
\f[B]Note:\f[R] For a \f[CR]decodeAudioData()\f[R] example, see the
\f[CR]AudioContext.decodeAudioData()\f[R] page.
.RE
.SH SEE ALSO
.IP \[bu] 2
Using the Web Audio API
.IP \[bu] 2
Web Audio API
